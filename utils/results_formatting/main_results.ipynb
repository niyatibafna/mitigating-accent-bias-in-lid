{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required format:\n",
    "\n",
    "# \t\t\t\t\t\t\tFLEURS\tEdAcc\tCV\n",
    "# ET\n",
    "# duseqs,w2v2-att4-1000\n",
    "# phoneseqs,vl107,att=8\n",
    "# ET+PS_combo\n",
    "# ET+duseq_linear\n",
    "# ET+duseqembed\n",
    "# ET+PS_linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_edacc_results(predictions_dir):\n",
    "    \n",
    "    predictions_path = predictions_dir + \"/edacc_predictions.pkl\"\n",
    "    if not os.path.exists(predictions_path):\n",
    "        predictions_path = predictions_dir + \"/predictions.pkl\"\n",
    "\n",
    "    if not os.path.exists(predictions_path):\n",
    "        print(f\"No predictions found in the specified directory: {predictions_dir}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    with open(predictions_path, \"rb\") as f:\n",
    "        eval_data = pkl.load(f)\n",
    "\n",
    "    results_by_accent = defaultdict(lambda: defaultdict(int))\n",
    "    # print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "    for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "        if prediction == label:\n",
    "            results_by_accent[accent][\"correct\"] += 1\n",
    "        results_by_accent[accent][\"total\"] += 1\n",
    "    # %%\n",
    "\n",
    "    # Merge \"us\" and \"american\"  accents\n",
    "    results_by_accent[\"us\"] = {k: results_by_accent[\"us\"].get(k, 0) + results_by_accent[\"american\"].get(k, 0) for k in set(results_by_accent[\"us\"]) | set(results_by_accent[\"american\"])}\n",
    "    # results_by_accent[\"us\"][\"total\"] = sum([results_by_accent[\"us\"][\"total\"], results_by_accent[\"american\"][\"total\"]])\n",
    "    del results_by_accent[\"american\"]\n",
    "\n",
    "    # Compute macro-average accuracy, ignoring accents with < 10 samples\n",
    "    acc_by_accent = {accent: results_by_accent[accent][\"correct\"]/results_by_accent[accent][\"total\"] \\\n",
    "                        for accent in results_by_accent}\n",
    "\n",
    "    macro_avg = np.mean([acc for accent, acc in acc_by_accent.items() if results_by_accent[accent][\"total\"] >= 10])\n",
    "    micro_avg = sum([results_by_accent[accent][\"correct\"] for accent in results_by_accent]) \\\n",
    "        / sum([results_by_accent[accent][\"total\"] for accent in results_by_accent])\n",
    "    std_dev = np.std([acc for accent, acc in acc_by_accent.items() if results_by_accent[accent][\"total\"] >= 10])\n",
    "    \n",
    "    return results_by_accent, macro_avg, micro_avg, std_dev\n",
    "\n",
    "\n",
    "\n",
    "def read_edacc_for_bootstrap_ci(predictions_dir):\n",
    "    '''\n",
    "    Should return a list of tuples [(pred, label, speaker_id)]\n",
    "    '''\n",
    "    \n",
    "    predictions_path = predictions_dir + \"/edacc_predictions.pkl\"\n",
    "    if not os.path.exists(predictions_path):\n",
    "        predictions_path = predictions_dir + \"/predictions.pkl\"\n",
    "\n",
    "    if not os.path.exists(predictions_path):\n",
    "        print(f\"No predictions found in the specified directory: {predictions_dir}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    with open(predictions_path, \"rb\") as f:\n",
    "        eval_data = pkl.load(f)\n",
    "\n",
    "    \n",
    "    data = []\n",
    "    for pred, label, accent, audio_file in zip(eval_data[\"preds\"], eval_data[\"labels\"], eval_data[\"accents\"], eval_data[\"audio_files\"]):\n",
    "        data.append((pred, label, accent, audio_file))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_cv_results(predictions_dir):\n",
    "    predictions_path = predictions_dir + \"/cv_predictions.pkl\"\n",
    "    with open(predictions_path, \"rb\") as f:\n",
    "        eval_data = pkl.load(f)\n",
    "\n",
    "    results_by_accent = defaultdict(lambda: defaultdict(int))\n",
    "    # print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "    for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "        if prediction == label:\n",
    "            results_by_accent[accent][\"correct\"] += 1\n",
    "        results_by_accent[accent][\"total\"] += 1\n",
    "\n",
    "    # Compute macro-average accuracy, ignoring accents with < 10 samples\n",
    "    acc_by_accent = {accent: results_by_accent[accent][\"correct\"]/results_by_accent[accent][\"total\"] \\\n",
    "                        for accent in results_by_accent}\n",
    "\n",
    "    macro_avg = np.mean([acc for accent, acc in acc_by_accent.items() if results_by_accent[accent][\"total\"] >= 10])\n",
    "    micro_avg = sum([results_by_accent[accent][\"correct\"] for accent in results_by_accent]) \\\n",
    "        / sum([results_by_accent[accent][\"total\"] for accent in results_by_accent])\n",
    "    std_dev = np.std([acc for accent, acc in acc_by_accent.items() if results_by_accent[accent][\"total\"] >= 10])\n",
    "    \n",
    "    return results_by_accent, macro_avg, micro_avg, std_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_cv_from_hf_results(predictions_dir):\n",
    "    predictions_path = predictions_dir + \"/cv_from_hf_predictions.pkl\"\n",
    "    with open(predictions_path, \"rb\") as f:\n",
    "        eval_data = pkl.load(f)\n",
    "\n",
    "    results_by_accent = defaultdict(lambda: defaultdict(int))\n",
    "    # print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "    for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "        if prediction == label:\n",
    "            results_by_accent[accent][\"correct\"] += 1\n",
    "        results_by_accent[accent][\"total\"] += 1\n",
    "\n",
    "    # Compute macro-average accuracy, ignoring accents with < 10 samples\n",
    "    acc_by_accent = {accent: results_by_accent[accent][\"correct\"]/results_by_accent[accent][\"total\"] \\\n",
    "                        for accent in results_by_accent}\n",
    "\n",
    "    macro_avg = np.mean([acc for accent, acc in acc_by_accent.items() if results_by_accent[accent][\"total\"] >= 10])\n",
    "    micro_avg = sum([results_by_accent[accent][\"correct\"] for accent in results_by_accent]) \\\n",
    "        / sum([results_by_accent[accent][\"total\"] for accent in results_by_accent])\n",
    "    std_dev = np.std([acc for accent, acc in acc_by_accent.items() if results_by_accent[accent][\"total\"] >= 10])\n",
    "    \n",
    "    return results_by_accent, macro_avg, micro_avg, std_dev\n",
    "\n",
    "\n",
    "def read_cv_from_hf_l2_results(predictions_dir):\n",
    "    predictions_path = predictions_dir + \"/cv_from_hf_predictions.pkl\"\n",
    "    with open(predictions_path, \"rb\") as f:\n",
    "        eval_data = pkl.load(f)\n",
    "\n",
    "    results_by_accent = defaultdict(lambda: defaultdict(int))\n",
    "    l2_accents = {\"de_Amerikanisches Deutsch\",\n",
    "        \"de_Britisches Deutsch\",\n",
    "        \"de_Schweizerdeutsch\",\n",
    "        \"de_Französisch Deutsch\",\n",
    "        \"de_Italienisch Deutsch\",\n",
    "        \"de_Polnisch Deutsch\",\n",
    "        \"de_Russisch Deutsch\",\n",
    "        \"fr_Français de Suisse\",\n",
    "        \"fr_Français des États-Unis\",\n",
    "        \"fr_Français du Royaume-Uni\",\n",
    "        \"fr_Français d’Allemagne\"}\n",
    "    # print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "    for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "        if f\"{label}_{accent.strip()}\" not in l2_accents:\n",
    "            continue\n",
    "        if prediction == label:\n",
    "            results_by_accent[accent][\"correct\"] += 1\n",
    "        results_by_accent[accent][\"total\"] += 1\n",
    "\n",
    "    # Compute macro-average accuracy, ignoring accents with < 10 samples\n",
    "    acc_by_accent = {accent: results_by_accent[accent][\"correct\"]/results_by_accent[accent][\"total\"] \\\n",
    "                        for accent in results_by_accent}\n",
    "\n",
    "    macro_avg = np.mean([acc for accent, acc in acc_by_accent.items() if results_by_accent[accent][\"total\"] >= 10])\n",
    "    micro_avg = sum([results_by_accent[accent][\"correct\"] for accent in results_by_accent]) \\\n",
    "        / sum([results_by_accent[accent][\"total\"] for accent in results_by_accent])\n",
    "    std_dev = np.std([acc for accent, acc in acc_by_accent.items() if results_by_accent[accent][\"total\"] >= 10])\n",
    "    \n",
    "    return results_by_accent, macro_avg, micro_avg, std_dev\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fleurs_results(predictions_dir):\n",
    "\n",
    "    predictions_path = predictions_dir + \"/fleurs_test_predictions.pkl\"\n",
    "\n",
    "    with open(predictions_path, \"rb\") as f:\n",
    "        eval_data = pkl.load(f)\n",
    "\n",
    "    results_by_lang = defaultdict(lambda: defaultdict(int))\n",
    "    # print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "    for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "        if prediction == label:\n",
    "            results_by_lang[label][\"correct\"] += 1\n",
    "        results_by_lang[label][\"total\"] += 1\n",
    "    \n",
    "    # Compute macro-average accuracy, ignoring accents with < 10 samples\n",
    "    acc_by_accent = {lang: results_by_lang[lang][\"correct\"]/results_by_lang[lang][\"total\"] \\\n",
    "                        for lang in results_by_lang}\n",
    "\n",
    "    macro_avg = np.mean([acc for lang, acc in acc_by_accent.items() if results_by_lang[lang][\"total\"] >= 10])\n",
    "    micro_avg = sum([results_by_lang[lang][\"correct\"] for lang in results_by_lang]) \\\n",
    "        / sum([results_by_lang[lang][\"total\"] for lang in results_by_lang])\n",
    "    std_dev = np.std([acc for lang, acc in acc_by_accent.items() if results_by_lang[lang][\"total\"] >= 10])\n",
    "    \n",
    "    return results_by_lang, macro_avg, micro_avg, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required format:\n",
    "\n",
    "# \t\t\t\t\t\t\tFLEURS\tEdAcc\tCV\n",
    "# ET\n",
    "# duseqs,w2v2-att4-1000\n",
    "# phoneseqs,vl107,att=8\n",
    "# ET+phoneseqs_combo\n",
    "# ET+duseq_train\n",
    "# ET+duseqembed\n",
    "# ET+phoneseqs_train\n",
    "\n",
    "\n",
    "approach2dir = {\n",
    "    \"ET\": \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/formatted\",\n",
    "    \"duseqs\": \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/wav2vec2_intermediate_outputs/vl107/wav2vec2-base-layer8-1000/cnn-attentions-linear-4/lid_model_outputs/\",\n",
    "    \"ET+duseq-train\": \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps_phoneseqs_duseqs_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft_wav2vec2-base-layer8-1000/attentions-linear-4/reps-phoneseq-duseqs_lid_model_outputs\",\n",
    "    \"ET+duseqembed-train\": \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps_phoneseqs_duseqembed_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft_wav2vec2-base-layer8-1000/attentions-linear-4/reps-phoneseq-duseqs_lid_model_outputs\",\n",
    "    \"phoneseqs\": \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/phoneseq_exps/vl107/wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/phoneseq_lid_model_outputs/\",\n",
    "    \"ET+phoneseqs\": \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/dists-phoneseq-systemcombo_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/lid_model_outputs/\",\n",
    "    \"ET+phoneseqs-train\": \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps-phoneseq_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/reps-phoneseq_lid_model_outputs/\",\n",
    "\n",
    "}\n",
    "\n",
    "dataset_to_processor = {\"fleurs_test\": read_fleurs_results, \"cv\": read_cv_results,\\\n",
    "                         \"edacc\": read_edacc_results, \"cv_from_hf\": read_cv_from_hf_results, \\\n",
    "                            \"cv_from_hf_l2\": read_cv_from_hf_l2_results}\n",
    "\n",
    "results = defaultdict(lambda: defaultdict(dict))\n",
    "for approach, dir in approach2dir.items():\n",
    "    for dataset in [\"fleurs_test\", \"edacc\", \"cv\", \"cv_from_hf\", \"cv_from_hf_l2\"]:\n",
    "        results_by_variety, macro_avg, micro_avg, std_dev = dataset_to_processor[dataset](dir)\n",
    "        results[approach][dataset][\"macro_avg\"] = round(macro_avg*100, 1)\n",
    "        results[approach][dataset][\"micro_avg\"] = round(micro_avg*100, 1)\n",
    "        results[approach][dataset][\"std_dev\"] = round(std_dev*100, 1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fleurs_test</th>\n",
       "      <th>edacc</th>\n",
       "      <th>cv</th>\n",
       "      <th>cv_from_hf</th>\n",
       "      <th>cv_from_hf_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>(89.3, 89.5, 17.2)</td>\n",
       "      <td>(52.7, 57.0, 26.0)</td>\n",
       "      <td>(77.0, 68.7, 25.2)</td>\n",
       "      <td>(83.0, 81.3, 19.0)</td>\n",
       "      <td>(69.8, 63.3, 20.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duseqs</th>\n",
       "      <td>(49.6, 49.8, 18.3)</td>\n",
       "      <td>(46.1, 49.8, 17.7)</td>\n",
       "      <td>(73.5, 68.3, 16.9)</td>\n",
       "      <td>(49.6, 51.5, 16.3)</td>\n",
       "      <td>(50.5, 48.0, 16.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET+duseq-train</th>\n",
       "      <td>(84.7, 84.9, 18.9)</td>\n",
       "      <td>(54.6, 59.3, 23.8)</td>\n",
       "      <td>(78.3, 71.4, 19.0)</td>\n",
       "      <td>(82.3, 81.0, 17.8)</td>\n",
       "      <td>(70.9, 65.3, 22.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET+duseqembed-train</th>\n",
       "      <td>(84.3, 84.2, 20.2)</td>\n",
       "      <td>(57.3, 61.6, 23.0)</td>\n",
       "      <td>(79.3, 72.2, 18.0)</td>\n",
       "      <td>(77.9, 73.9, 20.0)</td>\n",
       "      <td>(68.6, 61.0, 22.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phoneseqs</th>\n",
       "      <td>(52.9, 52.5, 22.7)</td>\n",
       "      <td>(41.9, 46.4, 22.6)</td>\n",
       "      <td>(76.2, 71.4, 14.3)</td>\n",
       "      <td>(53.4, 56.1, 18.7)</td>\n",
       "      <td>(49.1, 53.0, 16.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET+phoneseqs</th>\n",
       "      <td>(89.5, 89.5, 17.8)</td>\n",
       "      <td>(56.7, 61.0, 25.9)</td>\n",
       "      <td>(82.2, 77.2, 19.0)</td>\n",
       "      <td>(83.0, 82.7, 17.1)</td>\n",
       "      <td>(70.5, 68.4, 19.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET+phoneseqs-train</th>\n",
       "      <td>(86.6, 86.4, 18.2)</td>\n",
       "      <td>(60.9, 65.1, 24.8)</td>\n",
       "      <td>(88.0, 84.8, 10.9)</td>\n",
       "      <td>(84.6, 81.9, 15.4)</td>\n",
       "      <td>(74.8, 75.7, 14.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            fleurs_test               edacc  \\\n",
       "ET                   (89.3, 89.5, 17.2)  (52.7, 57.0, 26.0)   \n",
       "duseqs               (49.6, 49.8, 18.3)  (46.1, 49.8, 17.7)   \n",
       "ET+duseq-train       (84.7, 84.9, 18.9)  (54.6, 59.3, 23.8)   \n",
       "ET+duseqembed-train  (84.3, 84.2, 20.2)  (57.3, 61.6, 23.0)   \n",
       "phoneseqs            (52.9, 52.5, 22.7)  (41.9, 46.4, 22.6)   \n",
       "ET+phoneseqs         (89.5, 89.5, 17.8)  (56.7, 61.0, 25.9)   \n",
       "ET+phoneseqs-train   (86.6, 86.4, 18.2)  (60.9, 65.1, 24.8)   \n",
       "\n",
       "                                     cv          cv_from_hf  \\\n",
       "ET                   (77.0, 68.7, 25.2)  (83.0, 81.3, 19.0)   \n",
       "duseqs               (73.5, 68.3, 16.9)  (49.6, 51.5, 16.3)   \n",
       "ET+duseq-train       (78.3, 71.4, 19.0)  (82.3, 81.0, 17.8)   \n",
       "ET+duseqembed-train  (79.3, 72.2, 18.0)  (77.9, 73.9, 20.0)   \n",
       "phoneseqs            (76.2, 71.4, 14.3)  (53.4, 56.1, 18.7)   \n",
       "ET+phoneseqs         (82.2, 77.2, 19.0)  (83.0, 82.7, 17.1)   \n",
       "ET+phoneseqs-train   (88.0, 84.8, 10.9)  (84.6, 81.9, 15.4)   \n",
       "\n",
       "                          cv_from_hf_l2  \n",
       "ET                   (69.8, 63.3, 20.9)  \n",
       "duseqs               (50.5, 48.0, 16.5)  \n",
       "ET+duseq-train       (70.9, 65.3, 22.7)  \n",
       "ET+duseqembed-train  (68.6, 61.0, 22.6)  \n",
       "phoneseqs            (49.1, 53.0, 16.7)  \n",
       "ET+phoneseqs         (70.5, 68.4, 19.1)  \n",
       "ET+phoneseqs-train   (74.8, 75.7, 14.0)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n",
    "results_formatted = {approach: {dataset: (results[approach][dataset][\"micro_avg\"], results[approach][dataset][\"macro_avg\"], results[approach][dataset][\"std_dev\"]) for dataset in results[approach]} for approach in results}\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results_formatted)\n",
    "\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      " & fleurs_test & edacc & cv \\\\\n",
      "\\midrule\n",
      "ET & 89.3 & 89.5±17.2 & 52.7 & 57.0±26.0 & 77.0 & 68.7±25.2 \\\\\n",
      "duseqs & 49.6 & 49.8±18.3 & 46.1 & 49.8±17.7 & 73.5 & 68.3±16.9 \\\\\n",
      "ET+duseq-train & 84.7 & 84.9±18.9 & 54.6 & 59.3±23.8 & 78.3 & 71.4±19.0 \\\\\n",
      "ET+duseqembed-train & 84.3 & 84.2±20.2 & 57.3 & 61.6±23.0 & 79.3 & 72.2±18.0 \\\\\n",
      "phoneseqs & 53.0 & 52.6±22.7 & 41.9 & 46.5±22.6 & 76.3 & 71.4±14.3 \\\\\n",
      "ET+phoneseqs & 89.5 & 89.5±17.8 & 56.7 & 61.0±25.9 & 82.2 & 77.2±19.0 \\\\\n",
      "ET+phoneseqs-train & 86.6 & 86.4±18.2 & 60.9 & 65.1±24.8 & 88.0 & 84.8±10.9 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_formatted = {approach: {dataset: f\"{results[approach][dataset][\"micro_avg\"]} & {results[approach][dataset][\"macro_avg\"]}{chr(177)}{results[approach][dataset][\"std_dev\"]}\" for dataset in results[approach]} for approach in results}\n",
    "df = pd.DataFrame(results_formatted)\n",
    "\n",
    "print(df.T.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET & 89.3 & 89.5$\\pm$17.2 & 77.0 & 68.7$\\pm$25.2 & 52.7 & 57.0$\\pm$26.0 \\\n",
      "duseqs & 49.6 & 49.8$\\pm$18.3 & 73.5 & 68.3$\\pm$16.9 & 46.1 & 49.8$\\pm$17.7 \\\n",
      "ET+duseq-train & 85.8 & 85.8$\\pm$18.8 & 74.5 & 66.4$\\pm$19.9 & 49.4 & 53.6$\\pm$22.7 \\\n",
      "ET+duseqembed-train & 85.8 & 85.8$\\pm$18.9 & 79.9 & 73.3$\\pm$19.2 & 59.0 & 63.1$\\pm$22.4 \\\n",
      "phoneseqs & 53.0 & 52.6$\\pm$22.7 & 76.3 & 71.4$\\pm$14.3 & 41.9 & 46.5$\\pm$22.6 \\\n",
      "ET+phoneseqs & 89.5 & 89.5$\\pm$17.8 & 82.2 & 77.2$\\pm$19.0 & 56.7 & 61.0$\\pm$25.9 \\\n",
      "ET+phoneseqs-train & 86.6 & 86.4$\\pm$18.2 & 88.0 & 84.8$\\pm$10.9 & 60.9 & 65.1$\\pm$24.8 \\\n"
     ]
    }
   ],
   "source": [
    "s = '''ET & 89.3 & 89.5±17.2 & 77.0 & 68.7±25.2 & 52.7 & 57.0±26.0 \\\\\n",
    "duseqs & 49.6 & 49.8±18.3 & 73.5 & 68.3±16.9 & 46.1 & 49.8±17.7 \\\\\n",
    "ET+duseq-train & 85.8 & 85.8±18.8 & 74.5 & 66.4±19.9 & 49.4 & 53.6±22.7 \\\\\n",
    "ET+duseqembed-train & 85.8 & 85.8±18.9 & 79.9 & 73.3±19.2 & 59.0 & 63.1±22.4 \\\\\n",
    "phoneseqs & 53.0 & 52.6±22.7 & 76.3 & 71.4±14.3 & 41.9 & 46.5±22.6 \\\\\n",
    "ET+phoneseqs & 89.5 & 89.5±17.8 & 82.2 & 77.2±19.0 & 56.7 & 61.0±25.9 \\\\\n",
    "ET+phoneseqs-train & 86.6 & 86.4±18.2 & 88.0 & 84.8±10.9 & 60.9 & 65.1±24.8 \\\\'''\n",
    "print(s.replace(\"±\", \"$\\\\pm$\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar_predictions.pkl\n",
      "bg_predictions.pkl\n",
      "af_predictions.pkl\n",
      "am_predictions.pkl\n",
      "az_predictions.pkl\n",
      "bn_predictions.pkl\n",
      "as_predictions.pkl\n",
      "bs_predictions.pkl\n",
      "ca_predictions.pkl\n",
      "be_predictions.pkl\n",
      "ceb_predictions.pkl\n",
      "cs_predictions.pkl\n",
      "el_predictions.pkl\n",
      "en_predictions.pkl\n",
      "da_predictions.pkl\n",
      "de_predictions.pkl\n",
      "es_predictions.pkl\n",
      "et_predictions.pkl\n",
      "cy_predictions.pkl\n",
      "fr_predictions.pkl\n",
      "fi_predictions.pkl\n",
      "fa_predictions.pkl\n",
      "gl_predictions.pkl\n",
      "hi_predictions.pkl\n",
      "is_predictions.pkl\n",
      "gu_predictions.pkl\n",
      "hr_predictions.pkl\n",
      "ha_predictions.pkl\n",
      "id_predictions.pkl\n",
      "hu_predictions.pkl\n",
      "hy_predictions.pkl\n",
      "ja_predictions.pkl\n",
      "it_predictions.pkl\n",
      "ko_predictions.pkl\n",
      "ka_predictions.pkl\n",
      "km_predictions.pkl\n",
      "kk_predictions.pkl\n",
      "kn_predictions.pkl\n",
      "lo_predictions.pkl\n",
      "lb_predictions.pkl\n",
      "ln_predictions.pkl\n",
      "lt_predictions.pkl\n",
      "lv_predictions.pkl\n",
      "mn_predictions.pkl\n",
      "mk_predictions.pkl\n",
      "ms_predictions.pkl\n",
      "ml_predictions.pkl\n",
      "nl_predictions.pkl\n",
      "mr_predictions.pkl\n",
      "mt_predictions.pkl\n",
      "mi_predictions.pkl\n",
      "ne_predictions.pkl\n",
      "pa_predictions.pkl\n",
      "my_predictions.pkl\n",
      "pl_predictions.pkl\n",
      "ps_predictions.pkl\n",
      "ro_predictions.pkl\n",
      "ru_predictions.pkl\n",
      "pt_predictions.pkl\n",
      "oc_predictions.pkl\n",
      "sl_predictions.pkl\n",
      "sk_predictions.pkl\n",
      "sd_predictions.pkl\n",
      "sr_predictions.pkl\n",
      "sn_predictions.pkl\n",
      "sv_predictions.pkl\n",
      "te_predictions.pkl\n",
      "sw_predictions.pkl\n",
      "ta_predictions.pkl\n",
      "so_predictions.pkl\n",
      "ur_predictions.pkl\n",
      "tg_predictions.pkl\n",
      "uk_predictions.pkl\n",
      "th_predictions.pkl\n",
      "tr_predictions.pkl\n",
      "vi_predictions.pkl\n",
      "uz_predictions.pkl\n",
      "yo_predictions.pkl\n"
     ]
    }
   ],
   "source": [
    "######## ARCHIVE: Moving ET Fleurs position into consistent format\n",
    "\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "dirpath = \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/fleurs_test_predictions\"\n",
    "outdir = \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/formatted/\"\n",
    "all_labels, all_preds, all_accents = [], [], []\n",
    "for filepath in os.listdir(dirpath):\n",
    "    print(filepath)\n",
    "    predictions_path = os.path.join(dirpath, filepath)\n",
    "    # Merge into a single pkl file \n",
    "    with open(predictions_path, \"rb\") as f:\n",
    "        eval_data = pkl.load(f)\n",
    "        all_labels.extend(eval_data[\"labels\"])\n",
    "        all_preds.extend(eval_data[\"preds\"])\n",
    "        all_accents.extend(eval_data[\"accents\"])\n",
    "with open(os.path.join(outdir, \"fleurs_test_predictions.pkl\"), \"wb\") as f:\n",
    "    pkl.dump({\"labels\": all_labels, \"preds\": all_preds, \"accents\": all_accents}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accent_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
