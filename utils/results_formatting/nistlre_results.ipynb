{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for ar_acm: 0.444\n",
      "Total samples for ar_acm: 1000\n",
      "\n",
      "Accuracy for ar_apc: 0.454\n",
      "Total samples for ar_apc: 1000\n",
      "\n",
      "Accuracy for ar_ary: 0.451\n",
      "Total samples for ar_ary: 1000\n",
      "\n",
      "Accuracy for ar_arz: 0.53\n",
      "Total samples for ar_arz: 1000\n",
      "\n",
      "Accuracy for en_gbr: 0.462\n",
      "Total samples for en_gbr: 1000\n",
      "\n",
      "Accuracy for en_usg: 0.431\n",
      "Total samples for en_usg: 1000\n",
      "\n",
      "Accuracy for es_car: 0.267\n",
      "Total samples for es_car: 1000\n",
      "\n",
      "Accuracy for es_eur: 0.16\n",
      "Total samples for es_eur: 1000\n",
      "\n",
      "Accuracy for es_lac: 0.372\n",
      "Total samples for es_lac: 1000\n",
      "\n",
      "Accuracy for pt_brz: 0.546\n",
      "Total samples for pt_brz: 1000\n",
      "\n",
      "Accuracy for zh_cmn: 0.763\n",
      "Total samples for zh_cmn: 1000\n",
      "\n",
      "Accuracy for zh_nan: 0.203\n",
      "Total samples for zh_nan: 1000\n",
      "\n",
      "Total accuracy: 0.4235833333333333\n",
      "44.4\n",
      "45.4\n",
      "45.1\n",
      "53.0\n",
      "46.2\n",
      "43.1\n",
      "26.7\n",
      "16.0\n",
      "37.2\n",
      "54.6\n",
      "76.3\n",
      "20.3\n",
      "0.4235833333333333\n",
      "ar_acm\n",
      "ar_apc\n",
      "ar_ary\n",
      "ar_arz\n",
      "en_gbr\n",
      "en_usg\n",
      "es_car\n",
      "es_eur\n",
      "es_lac\n",
      "pt_brz\n",
      "zh_cmn\n",
      "zh_nan\n"
     ]
    }
   ],
   "source": [
    "# predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps-phoneseq_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/reps-phoneseq_lid_model_outputs/nistlre_predictions.pkl\"\n",
    "# predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps-phoneseq_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-4/reps-phoneseq_lid_model_outputs/nistlre_predictions.pkl\"\n",
    "# predictions_path = \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/formatted/nistlre_predictions.pkl\"\n",
    "predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/dists-phoneseq-systemcombo_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/lid_model_outputs/nistlre_predictions.pkl\"\n",
    "# output_path = \"wav2vec2-base-layer8-100/accuracy.csv\"\n",
    "\n",
    "output_path = None\n",
    "\n",
    "with open(predictions_path, \"rb\") as f:\n",
    "    eval_data = pkl.load(f)\n",
    "\n",
    "results_by_lang = defaultdict(lambda: defaultdict(int))\n",
    "# print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "    lang_accent = f\"{label}_{accent}\"\n",
    "    if prediction == label:\n",
    "        results_by_lang[lang_accent][\"correct\"] += 1\n",
    "    results_by_lang[lang_accent][\"total\"] += 1\n",
    "# %%\n",
    "\n",
    "for lang, results in results_by_lang.items():\n",
    "    results_by_lang[lang][\"accuracy\"] = round(results[\"correct\"]*100/results[\"total\"], 1)\n",
    "    print(f\"Accuracy for {lang}: {results['correct']/results['total']}\")\n",
    "    print(f\"Total samples for {lang}: {results['total']}\")\n",
    "    print()\n",
    "\n",
    "accuracy = sum([results[\"correct\"] for results in results_by_lang.values()])/sum([results[\"total\"] for results in results_by_lang.values()])\n",
    "print(f\"Total accuracy: {accuracy}\")\n",
    "\n",
    "lang_accents = list(results_by_lang.keys())\n",
    "lang_accents.sort()\n",
    "\n",
    "for lang_accent in lang_accents:\n",
    "    print(f\"{results_by_lang[lang_accent]['accuracy']}\")\n",
    "print(f\"{accuracy}\")\n",
    "\n",
    "print(*lang_accents, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.4206666666666667\n"
     ]
    }
   ],
   "source": [
    "predictions_path = \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/formatted/nistlre_predictions.pkl\"\n",
    "# output_path = \"wav2vec2-base-layer8-100/accuracy.csv\"\n",
    "\n",
    "output_path = None\n",
    "\n",
    "with open(predictions_path, \"rb\") as f:\n",
    "    eval_data = pkl.load(f)\n",
    "\n",
    "results_by_lang = defaultdict(lambda: defaultdict(int))\n",
    "# print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "    if prediction == label:\n",
    "        results_by_lang[accent][\"correct\"] += 1\n",
    "    results_by_lang[accent][\"total\"] += 1\n",
    "# %%\n",
    "\n",
    "for lang, results in results_by_lang.items():\n",
    "    results_by_lang[lang][\"accuracy\"] = round(results[\"correct\"]/results[\"total\"], 1)\n",
    "    # print(f\"Accuracy for {lang}: {results['correct']/results['total']}\")\n",
    "    # print(f\"Total samples for {lang}: {results['total']}\")\n",
    "    # print()\n",
    "\n",
    "accuracy = sum([results[\"correct\"] for results in results_by_lang.values()])/sum([results[\"total\"] for results in results_by_lang.values()])\n",
    "print(f\"Total accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle as pkl\n",
    "nistlre_path = \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/nistlre_predictions/\"\n",
    "\n",
    "preds = []\n",
    "accents = []\n",
    "labels = []\n",
    "\n",
    "for file in os.listdir(nistlre_path):\n",
    "    with open(os.path.join(nistlre_path, file), \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "        preds.extend(data[\"preds\"])\n",
    "        accents.extend(data[\"accents\"])\n",
    "        labels.extend(data[\"labels\"])\n",
    "\n",
    "output_path = \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/formatted/\"\n",
    "with open(os.path.join(output_path, \"nistlre_predictions.pkl\"), \"wb\") as f:\n",
    "    pkl.dump({\"preds\": preds, \"accents\": accents, \"labels\": labels}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle as pkl\n",
    "nistlre_path = \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/cv_from_hf_predictions/\"\n",
    "\n",
    "preds = []\n",
    "accents = []\n",
    "labels = []\n",
    "\n",
    "for file in os.listdir(nistlre_path):\n",
    "    with open(os.path.join(nistlre_path, file), \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "        preds.extend(data[\"preds\"])\n",
    "        accents.extend(data[\"accents\"])\n",
    "        labels.extend(data[\"labels\"])\n",
    "\n",
    "output_path = \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/formatted/\"\n",
    "with open(os.path.join(output_path, \"cv_from_hf_predictions.pkl\"), \"wb\") as f:\n",
    "    pkl.dump({\"preds\": preds, \"accents\": accents, \"labels\": labels}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.7668320340184267\n",
      "55.1\n",
      "92.2\n",
      "67.2\n",
      "86.7\n",
      "66.7\n",
      "88.8\n",
      "74.9\n",
      "95.1\n",
      "52.9\n",
      "88.2\n",
      "82.5\n",
      "76.7\n",
      "136\n",
      "51\n",
      "61\n",
      "15\n",
      "15\n",
      "98\n",
      "577\n",
      "183\n",
      "102\n",
      "110\n",
      "63\n",
      "de_Amerikanisches Deutsch\n",
      "de_Britisches Deutsch\n",
      "de_Französisch Deutsch\n",
      "de_Italienisch Deutsch\n",
      "de_Polnisch Deutsch\n",
      "de_Russisch Deutsch\n",
      "de_Schweizerdeutsch\n",
      "fr_Français de Suisse\n",
      "fr_Français des États-Unis\n",
      "fr_Français du Royaume-Uni\n",
      "fr_Français d’Allemagne\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "\n",
    "# predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps-phoneseq_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/reps-phoneseq_lid_model_outputs/cv_from_hf_predictions.pkl\"\n",
    "predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps-phoneseq_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-4/reps-phoneseq_lid_model_outputs/cv_from_hf_predictions.pkl\"\n",
    "# predictions_path = \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/formatted/cv_from_hf_predictions.pkl\"\n",
    "# output_path = \"wav2vec2-base-layer8-100/accuracy.csv\"\n",
    "\n",
    "output_path = None\n",
    "\n",
    "with open(predictions_path, \"rb\") as f:\n",
    "    eval_data = pkl.load(f)\n",
    "\n",
    "results_by_lang = defaultdict(lambda: defaultdict(int))\n",
    "# print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "    # if label == \"it\":\n",
    "    #     continue\n",
    "    lang_accent = f\"{label}_{accent}\"\n",
    "    if prediction == label:\n",
    "        results_by_lang[lang_accent][\"correct\"] += 1\n",
    "    results_by_lang[lang_accent][\"total\"] += 1\n",
    "# %%\n",
    "\n",
    "# Let's throw out accents with less than 10 samples \n",
    "l2_accents = {\"de_Amerikanisches Deutsch\",\n",
    "\"de_Britisches Deutsch\",\n",
    "\"de_Schweizerdeutsch\",\n",
    "\"de_Französisch Deutsch\",\n",
    "\"de_Italienisch Deutsch\",\n",
    "\"de_Polnisch Deutsch\",\n",
    "\"de_Russisch Deutsch\",\n",
    "\"fr_Français de Suisse\",\n",
    "\"fr_Français des États-Unis\",\n",
    "\"fr_Français du Royaume-Uni\",\n",
    "\"fr_Français d’Allemagne\"}\n",
    "results_by_lang = {lang: results for lang, results in results_by_lang.items() if results[\"total\"] > 10 and lang in l2_accents}\n",
    "# results_by_lang = {lang: results for lang, results in results_by_lang.items() if results[\"total\"] > 10}\n",
    "\n",
    "\n",
    "for lang, results in results_by_lang.items():\n",
    "    results_by_lang[lang][\"accuracy\"] = round(results[\"correct\"]*100/results[\"total\"], 1)\n",
    "    # print(f\"Accuracy for {lang}: {results['correct']/results['total']}\")\n",
    "    # print(f\"Total samples for {lang}: {results['total']}\")\n",
    "    # print()\n",
    "\n",
    "accuracy = sum([results[\"correct\"] for results in results_by_lang.values()])/sum([results[\"total\"] for results in results_by_lang.values()])\n",
    "print(f\"Total accuracy: {accuracy}\")\n",
    "\n",
    "lang_accents = list(results_by_lang.keys())\n",
    "lang_accents.sort()\n",
    "\n",
    "for lang_accent in lang_accents:\n",
    "    print(f\"{results_by_lang[lang_accent]['accuracy']}\")\n",
    "print(f\"{round(accuracy*100, 1)}\")\n",
    "\n",
    "for lang_accent in lang_accents:\n",
    "    print(f\"{results_by_lang[lang_accent]['total']}\")\n",
    "\n",
    "print(*lang_accents, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'es_México': 532,\n",
       " 'es_Andino-Pacífico: Colombia, Perú, Ecuador, oeste de Bolivia y Venezuela andina': 382,\n",
       " 'es_América central': 176,\n",
       " 'es_España: Centro-Sur peninsular (Madrid, Toledo, Castilla-La Mancha)': 143,\n",
       " 'es_Rioplatense: Argentina, Uruguay, este de Bolivia, Paraguay': 213,\n",
       " 'es_España: Sur peninsular (Andalucia, Extremadura, Murcia)': 54,\n",
       " 'es_Chileno: Chile, Cuyo': 80,\n",
       " 'es_España: Norte peninsular (Asturias, Castilla y León, Cantabria, País Vasco, Navarra, Aragón, La Rioja, Guadalajara, Cuenca)': 167,\n",
       " 'es_Caribe: Cuba, Venezuela, Puerto Rico, República Dominicana, Panamá, Colombia caribeña, México caribeño, Costa del golfo de México': 245,\n",
       " 'es_España: Islas Canarias': 37,\n",
       " 'it_Calabrese': 16,\n",
       " 'it_Lieve Inflessione meridionale e romana': 18,\n",
       " 'it_Piemontese': 18,\n",
       " 'it_Italian native': 25,\n",
       " \"it_nord lombardia, della Valsassina ma un po' sporcato dal vivere a Milano\": 16,\n",
       " 'it_Sardo': 22,\n",
       " 'it_settentrionale': 32,\n",
       " 'it_Toscano,viareggino': 23,\n",
       " 'it_Northern': 23,\n",
       " 'it_Northern,Expat': 22,\n",
       " 'it_Italiano Standard,Romano': 20,\n",
       " 'it_Veneto': 375,\n",
       " 'it_Lombardo': 51,\n",
       " 'it_Toscano,Sud senese': 26,\n",
       " 'it_bresciano': 74,\n",
       " 'it_Emiliano': 85,\n",
       " 'it_Friulano': 43,\n",
       " 'it_Meridionale': 91,\n",
       " 'it_Tendente al siculo, ma non marcato': 491,\n",
       " 'de_Deutschland Deutsch': 1746,\n",
       " 'de_Schweizerdeutsch': 141,\n",
       " 'de_Österreichisches Deutsch': 122,\n",
       " 'de_Amerikanisches Deutsch': 43,\n",
       " 'de_Britisches Deutsch': 11,\n",
       " 'de_Französisch Deutsch': 20,\n",
       " 'de_Polnisch Deutsch': 15,\n",
       " 'de_Russisch Deutsch': 12,\n",
       " 'de_Italienisch Deutsch': 15,\n",
       " 'fr_Français de France': 1373,\n",
       " 'fr_Français du Canada': 109,\n",
       " 'fr_Français de Suisse': 40,\n",
       " 'fr_Français de Belgique': 48,\n",
       " 'fr_Français d’Allemagne': 11,\n",
       " 'fr_Français du Royaume-Uni': 28,\n",
       " 'fr_Français des États-Unis': 17}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals = {lang: results[\"total\"] for lang, results in results_by_lang.items()}\n",
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.8461326727222681\n",
      "53.7\n",
      "100.0\n",
      "88.9\n",
      "90.2\n",
      "83.3\n",
      "92.8\n",
      "92.3\n",
      "100.0\n",
      "63.9\n",
      "80.0\n",
      "55.2\n",
      "64.0\n",
      "90.9\n",
      "66.7\n",
      "84.7\n",
      "71.4\n",
      "61.5\n",
      "72.7\n",
      "88.8\n",
      "91.9\n",
      "89.9\n",
      "88.8\n",
      "91.1\n",
      "73.6\n",
      "89.1\n",
      "67.1\n",
      "85.7\n",
      "91.0\n",
      "95.5\n",
      "94.3\n",
      "89.7\n",
      "88.2\n",
      "100.0\n",
      "86.5\n",
      "95.2\n",
      "85.7\n",
      "95.6\n",
      "53.9\n",
      "38.9\n",
      "55.6\n",
      "90.4\n",
      "94.4\n",
      "90.0\n",
      "100.0\n",
      "82.5\n",
      "76.9\n",
      "57.5\n",
      "90.9\n",
      "100.0\n",
      "37.5\n",
      "89.4\n",
      "88.4\n",
      "100.0\n",
      "95.0\n",
      "55.6\n",
      "94.1\n",
      "97.8\n",
      "60.9\n",
      "95.5\n",
      "77.8\n",
      "77.3\n",
      "96.9\n",
      "57.7\n",
      "78.3\n",
      "68.5\n",
      "83.8\n",
      "93.8\n",
      "90.6\n",
      "84.6\n",
      "136\n",
      "11\n",
      "18\n",
      "51\n",
      "12\n",
      "222\n",
      "13\n",
      "12\n",
      "61\n",
      "15\n",
      "29\n",
      "25\n",
      "22\n",
      "15\n",
      "98\n",
      "577\n",
      "13\n",
      "22\n",
      "759\n",
      "222\n",
      "426\n",
      "269\n",
      "101\n",
      "144\n",
      "55\n",
      "210\n",
      "84\n",
      "222\n",
      "246\n",
      "298\n",
      "145\n",
      "17\n",
      "22\n",
      "37\n",
      "21\n",
      "14\n",
      "183\n",
      "102\n",
      "18\n",
      "45\n",
      "513\n",
      "18\n",
      "110\n",
      "24\n",
      "63\n",
      "13\n",
      "40\n",
      "11\n",
      "11\n",
      "16\n",
      "85\n",
      "43\n",
      "25\n",
      "20\n",
      "18\n",
      "51\n",
      "91\n",
      "23\n",
      "22\n",
      "18\n",
      "22\n",
      "491\n",
      "26\n",
      "23\n",
      "375\n",
      "74\n",
      "16\n",
      "32\n",
      "de_Amerikanisches Deutsch\n",
      "de_Belgisches Deutsch\n",
      "de_Brasilianisches Deutsch\n",
      "de_Britisches Deutsch\n",
      "de_Deutsch/Berlinern,Berlinerisch,klar,zart,feminin\n",
      "de_Deutschland Deutsch\n",
      "de_Deutschland Deutsch,Norddeutsch\n",
      "de_Deutschland Deutsch,leicht Berlinerisch\n",
      "de_Französisch Deutsch\n",
      "de_Italienisch Deutsch\n",
      "de_Kanadisches Deutsch\n",
      "de_Luxemburgisches Deutsch\n",
      "de_Niederländisch Deutsch\n",
      "de_Polnisch Deutsch\n",
      "de_Russisch Deutsch\n",
      "de_Schweizerdeutsch\n",
      "de_Tschechisch Deutsch\n",
      "de_liechtensteinisches Deutscher\n",
      "de_Österreichisches Deutsch\n",
      "es_América central\n",
      "es_Andino-Pacífico: Colombia, Perú, Ecuador, oeste de Bolivia y Venezuela andina\n",
      "es_Caribe: Cuba, Venezuela, Puerto Rico, República Dominicana, Panamá, Colombia caribeña, México caribeño, Costa del golfo de México\n",
      "es_Chileno: Chile, Cuyo\n",
      "es_España: Centro-Sur peninsular (Madrid, Toledo, Castilla-La Mancha)\n",
      "es_España: Islas Canarias\n",
      "es_España: Norte peninsular (Asturias, Castilla y León, Cantabria, País Vasco, Navarra, Aragón, La Rioja, Guadalajara, Cuenca)\n",
      "es_España: Sur peninsular (Andalucia, Extremadura, Murcia)\n",
      "es_México\n",
      "es_Rioplatense: Argentina, Uruguay, este de Bolivia, Paraguay\n",
      "fr_Français de Belgique\n",
      "fr_Français de France\n",
      "fr_Français de France,Accent du Sud Ouest, accent plat\n",
      "fr_Français de France,Parisien\n",
      "fr_Français de Guadeloupe\n",
      "fr_Français de La Réunion\n",
      "fr_Français de Roumanie\n",
      "fr_Français de Suisse\n",
      "fr_Français des États-Unis\n",
      "fr_Français du Bénin\n",
      "fr_Français du Cameroun\n",
      "fr_Français du Canada\n",
      "fr_Français du Maroc\n",
      "fr_Français du Royaume-Uni\n",
      "fr_Français d’Algérie\n",
      "fr_Français d’Allemagne\n",
      "fr_Français d’Autriche\n",
      "fr_Français d’Haïti\n",
      "fr_Français d’Italie\n",
      "fr_Sud-Ouest\n",
      "it_Calabrese\n",
      "it_Emiliano\n",
      "it_Friulano\n",
      "it_Italian native\n",
      "it_Italiano Standard,Romano\n",
      "it_Lieve Inflessione meridionale e romana\n",
      "it_Lombardo\n",
      "it_Meridionale\n",
      "it_Northern\n",
      "it_Northern,Expat\n",
      "it_Piemontese\n",
      "it_Sardo\n",
      "it_Tendente al siculo, ma non marcato\n",
      "it_Toscano,Sud senese\n",
      "it_Toscano,viareggino\n",
      "it_Veneto\n",
      "it_bresciano\n",
      "it_nord lombardia, della Valsassina ma un po' sporcato dal vivere a Milano\n",
      "it_settentrionale\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "\n",
    "predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps-phoneseq_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/reps-phoneseq_lid_model_outputs/cv_from_hf_predictions.pkl\"\n",
    "# predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps-phoneseq_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-4/reps-phoneseq_lid_model_outputs/cv_from_hf_predictions.pkl\"\n",
    "# predictions_path = \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/formatted/cv_from_hf_predictions.pkl\"\n",
    "# output_path = \"wav2vec2-base-layer8-100/accuracy.csv\"\n",
    "\n",
    "output_path = None\n",
    "\n",
    "with open(predictions_path, \"rb\") as f:\n",
    "    eval_data = pkl.load(f)\n",
    "\n",
    "results_by_lang = defaultdict(lambda: defaultdict(int))\n",
    "# print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "    # if label == \"it\":\n",
    "    #     continue\n",
    "    lang_accent = f\"{label}_{accent}\"\n",
    "    if prediction == label:\n",
    "        results_by_lang[lang_accent][\"correct\"] += 1\n",
    "    results_by_lang[lang_accent][\"total\"] += 1\n",
    "# %%\n",
    "\n",
    "# Let's throw out accents with less than 10 samples \n",
    "cv_from_hf_l2_accents = {\"de_Amerikanisches Deutsch\",\n",
    "        \"de_Brasilianisches Deutsch\",\n",
    "        \"de_Britisches Deutsch\",\n",
    "        \"de_Schweizerdeutsch\",\n",
    "        \"de_Französisch Deutsch\",\n",
    "        \"de_Kanadisches Deutsch\",\n",
    "        \"de_Italienisch Deutsch\",\n",
    "        \"de_Polnisch Deutsch\",\n",
    "        \"de_Russisch Deutsch\",\n",
    "        \"de_Tschechisch Deutsch\",\n",
    "        \"fr_Français de Suisse\",\n",
    "        \"fr_Français de Roumanie\",\n",
    "        \"fr_Français d’Autriche\",\n",
    "        \"fr_Français d’Italie\",\n",
    "        \"fr_Français des États-Unis\",\n",
    "        \"fr_Français du Royaume-Uni\",\n",
    "        \"fr_Français d’Allemagne\"}\n",
    "    \n",
    "# results_by_lang = {lang: results for lang, results in results_by_lang.items() if results[\"total\"] > 10 and lang in cv_from_hf_l2_accents}\n",
    "results_by_lang = {lang: results for lang, results in results_by_lang.items() if results[\"total\"] > 10}\n",
    "\n",
    "\n",
    "for lang, results in results_by_lang.items():\n",
    "    results_by_lang[lang][\"accuracy\"] = round(results[\"correct\"]*100/results[\"total\"], 1)\n",
    "    # print(f\"Accuracy for {lang}: {results['correct']/results['total']}\")\n",
    "    # print(f\"Total samples for {lang}: {results['total']}\")\n",
    "    # print()\n",
    "\n",
    "accuracy = sum([results[\"correct\"] for results in results_by_lang.values()])/sum([results[\"total\"] for results in results_by_lang.values()])\n",
    "print(f\"Total accuracy: {accuracy}\")\n",
    "\n",
    "lang_accents = list(results_by_lang.keys())\n",
    "lang_accents.sort()\n",
    "\n",
    "for lang_accent in lang_accents:\n",
    "    print(f\"{results_by_lang[lang_accent]['accuracy']}\")\n",
    "print(f\"{round(accuracy*100, 1)}\")\n",
    "\n",
    "for lang_accent in lang_accents:\n",
    "    print(f\"{results_by_lang[lang_accent]['total']}\")\n",
    "\n",
    "print(*lang_accents, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['preds', 'labels', 'accents', 'audio_files'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accent_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
