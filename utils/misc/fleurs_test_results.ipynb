{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'en': 737,\n",
       "         'ar': 3,\n",
       "         'la': 2,\n",
       "         'lt': 1,\n",
       "         'mt': 1,\n",
       "         'fa': 1,\n",
       "         'ceb': 1,\n",
       "         'id': 1})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang=\"en\"\n",
    "predictions_path = f\"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/fleurs_test_predictions/{lang}_predictions.pkl\"\n",
    "\n",
    "with open(predictions_path, \"rb\") as f:\n",
    "    eval_data = pkl.load(f)\n",
    "\n",
    "\n",
    "results_by_lang = defaultdict(lambda: defaultdict(int))\n",
    "# print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "lang_preds = []\n",
    "for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "    if label[:2] == lang:\n",
    "        lang_preds.append(prediction)\n",
    "\n",
    "Counter(lang_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHONESEQ models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'en': 715,\n",
       "         'cy': 26,\n",
       "         'nl': 1,\n",
       "         'tl': 1,\n",
       "         'gv': 1,\n",
       "         'sq': 1,\n",
       "         'kk': 1,\n",
       "         'af': 1})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/phoneseq_exps/vl107/wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/phoneseq_lid_model_outputs/fleurs_test_predictions.pkl\"\n",
    "with open(predictions_path, \"rb\") as f:\n",
    "    eval_data = pkl.load(f)\n",
    "\n",
    "lang = \"en\"\n",
    "results_by_lang = defaultdict(lambda: defaultdict(int))\n",
    "# print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "lang_preds = []\n",
    "for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "    if label[:len(lang)] == lang:\n",
    "        lang_preds.append(prediction)\n",
    "\n",
    "Counter(lang_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for PHONESEQ model on CV accents \n",
    "\n",
    "# predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/phoneseq_exps/vl107/wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/phoneseq_lid_model_outputs/cv_predictions.pkl\"\n",
    "predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/wav2vec2_intermediate_outputs/vl107/wav2vec2-base-layer8-1000/cnn-attentions-linear-8/lid_model_outputs/cv_predictions.pkl\"\n",
    "\n",
    "with open(predictions_path, \"rb\") as f:\n",
    "    eval_data = pkl.load(f)\n",
    "\n",
    "results_by_accent = defaultdict(lambda: defaultdict(int))\n",
    "confusion_matrix = defaultdict(lambda: defaultdict(int))\n",
    "# print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "    if prediction == label:\n",
    "        results_by_accent[accent][\"correct\"] += 1\n",
    "    results_by_accent[accent][\"total\"] += 1\n",
    "\n",
    "    confusion_matrix[accent][prediction] += 1\n",
    "# %%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for african\n",
      "defaultdict(<class 'int'>, {'total': 192, 'correct': 88})\n",
      "defaultdict(<class 'int'>, {'fi': 1, 'cy': 3, 'en': 88, 'no': 4, 'sl': 5, 'hu': 2, 'la': 10, 'af': 8, 'hr': 3, 'de': 9, 'nl': 4, 'ml': 1, 'sv': 5, 'ko': 1, 'lb': 4, 'lt': 2, 'id': 2, 'ru': 1, 'fo': 10, 'mt': 2, 'is': 2, 'bg': 1, 'gv': 1, 'sq': 4, 'tl': 4, 'vi': 1, 'as': 2, 'da': 2, 'eo': 1, 'yi': 1, 'pl': 1, 'sw': 1, 'nn': 1, 'fr': 1, 'ne': 1, 'uk': 1, 'ms': 1, 'mi': 1})\n"
     ]
    }
   ],
   "source": [
    "accent= \"african\"\n",
    "print(f\"Results for {accent}\")\n",
    "print(results_by_accent[accent])\n",
    "print(confusion_matrix[accent])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         us  england  hongkong  indian  african  australia  newzealand  \\\n",
      "en   4308.0    633.0       5.0   530.0     88.0      511.0       178.0   \n",
      "la    157.0     43.0       NaN    61.0     10.0       14.0        13.0   \n",
      "cy    230.0    151.0       2.0    47.0      3.0       87.0        12.0   \n",
      "gv     74.0     26.0       NaN     9.0      1.0       23.0         3.0   \n",
      "lv      8.0      6.0       NaN     8.0      NaN        5.0         NaN   \n",
      "..      ...      ...       ...     ...      ...        ...         ...   \n",
      "ta      NaN      NaN       NaN     2.0      NaN        NaN         NaN   \n",
      "su      NaN      NaN       NaN     2.0      NaN        NaN         NaN   \n",
      "sco     NaN      NaN       NaN     1.0      NaN        NaN         NaN   \n",
      "ne      NaN      NaN       NaN     NaN      1.0        NaN         NaN   \n",
      "si      NaN      NaN       NaN     NaN      NaN        NaN         NaN   \n",
      "\n",
      "     canada  scotland  ireland  philippines  wales  singapore  malaysia  \n",
      "en    755.0      46.0     75.0         43.0    NaN       74.0      15.0  \n",
      "la     23.0       6.0      NaN          3.0    NaN        9.0       1.0  \n",
      "cy     36.0       5.0      NaN          2.0    1.0        2.0       NaN  \n",
      "gv     20.0       1.0      2.0          1.0    NaN        1.0       NaN  \n",
      "lv      2.0       NaN      NaN          2.0    NaN        NaN       NaN  \n",
      "..      ...       ...      ...          ...    ...        ...       ...  \n",
      "ta      NaN       NaN      NaN          NaN    NaN        NaN       NaN  \n",
      "su      NaN       2.0      NaN          NaN    NaN        NaN       NaN  \n",
      "sco     NaN       NaN      NaN          NaN    NaN        NaN       NaN  \n",
      "ne      NaN       NaN      NaN          NaN    NaN        NaN       NaN  \n",
      "si      NaN       NaN      NaN          1.0    NaN        NaN       NaN  \n",
      "\n",
      "[101 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make csv for confusion matrix\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(confusion_matrix)\n",
    "print(df)\n",
    "df.to_csv(\"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/utils/misc/ssl_cv_confusion_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accent_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
