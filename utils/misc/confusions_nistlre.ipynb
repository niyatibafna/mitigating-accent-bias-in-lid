{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "output_path = None\n",
    "\n",
    "def load_results(predictions_path):\n",
    "    '''\n",
    "    Return dictionary with distribution of predictions by accent\n",
    "    '''\n",
    "    with open(predictions_path, \"rb\") as f:\n",
    "        eval_data = pkl.load(f)\n",
    "    \n",
    "    predictions_by_accent = defaultdict(lambda: defaultdict(int))\n",
    "    for prediction, accent in zip(eval_data[\"preds\"], eval_data[\"accents\"]):\n",
    "        predictions_by_accent[accent][prediction] += 1\n",
    "\n",
    "    return predictions_by_accent\n",
    "\n",
    "\n",
    "    # results_by_accent = defaultdict(lambda: defaultdict(int))\n",
    "    # print(list(zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"])))\n",
    "    # for prediction, accent, label in zip(eval_data[\"preds\"], eval_data[\"accents\"], eval_data[\"labels\"]):\n",
    "    #     if prediction == label:\n",
    "    #         results_by_accent[accent][\"correct\"] += 1\n",
    "    #     results_by_accent[accent][\"total\"] += 1\n",
    "    # # %%\n",
    "\n",
    "    # # Merge \"us\" and \"american\"  accents\n",
    "    # results_by_accent[\"us\"] = {k: results_by_accent[\"us\"].get(k, 0) + results_by_accent[\"american\"].get(k, 0) for k in set(results_by_accent[\"us\"]) | set(results_by_accent[\"american\"])}\n",
    "    # # results_by_accent[\"us\"][\"total\"] = sum([results_by_accent[\"us\"][\"total\"], results_by_accent[\"american\"][\"total\"]])\n",
    "    # del results_by_accent[\"american\"]\n",
    "\n",
    "\n",
    "    # for accent, results in results_by_accent.items():\n",
    "    #     results_by_accent[accent][\"accuracy\"] = round(results[\"correct\"]/results[\"total\"], 1)\n",
    "    #     print(f\"Accuracy for {accent}: {results['correct']/results['total']}\")\n",
    "    #     print(f\"Total samples for {accent}: {results['total']}\")\n",
    "    #     print()\n",
    "\n",
    "    return results_by_accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_3_confusions(preds_by_accent):\n",
    "    # Normalize the predictions\n",
    "    for accent, predictions in preds_by_accent.items():\n",
    "        total = sum(predictions.values()) - predictions[\"en\"]\n",
    "        for prediction, count in predictions.items():\n",
    "            preds_by_accent[accent][prediction] = round((count/total)*100, 1) if total > 0 else 0\n",
    "\n",
    "    # Print out the top 3 confusions for each accent\n",
    "    for accent, predictions in preds_by_accent.items():\n",
    "        print(f\"Top 3 confusions for {accent}:\")\n",
    "        for prediction, count in sorted([x for x in predictions.items() if x[0] != \"en\"], key=lambda x: x[1], reverse=True)[:3]:\n",
    "            print(f\"{prediction}: {count}\")\n",
    "        print()\n",
    "\n",
    "def get_top_3_confusions(preds_by_accent):\n",
    "    # Normalize the predictions\n",
    "    for accent, predictions in preds_by_accent.items():\n",
    "        total = sum(predictions.values())\n",
    "        for prediction, count in predictions.items():\n",
    "            preds_by_accent[accent][prediction] = round((count/total)*100, 1) if total > 0 else 0\n",
    "\n",
    "    top_confusions = defaultdict(lambda: defaultdict(float))\n",
    "    for accent, predictions in preds_by_accent.items():\n",
    "        for prediction, count in sorted([x for x in predictions.items()], key=lambda x: x[1], reverse=True)[:3]:\n",
    "            top_confusions[accent][prediction] = count\n",
    "\n",
    "    return top_confusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "etps_predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps-phoneseq_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/reps-phoneseq_lid_model_outputs/nistlre_predictions.pkl\"\n",
    "# predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps-phoneseq_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-4/reps-phoneseq_lid_model_outputs/nistlre_predictions.pkl\"\n",
    "ps_predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/phoneseq_exps/vl107/wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/phoneseq_lid_model_outputs/nistlre_new_predictions.pkl\"\n",
    "et_predictions_path = \"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/prelim_evals/preds/formatted/nistlre_predictions.pkl\"\n",
    "# predictions_path = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/dists-phoneseq-systemcombo_exps/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft/attentions-linear-8/lid_model_outputs/nistlre_predictions.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_preds_by_accent = load_results(et_predictions_path)\n",
    "etps_preds_by_accent = load_results(etps_predictions_path)\n",
    "ps_preds_by_accent = load_results(ps_predictions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_top_confusions = get_top_3_confusions(et_preds_by_accent)\n",
    "etps_top_confusions = get_top_3_confusions(etps_preds_by_accent)\n",
    "ps_top_confusions = get_top_3_confusions(ps_preds_by_accent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 confusions for brz:\n",
      "ET: [('pt', 52.1), ('yi', 9.3), ('ro', 8.9)]\n",
      "PS: [('pt', 26.4), ('ro', 8.5), ('ca', 6.1)]\n",
      "ET+PS: [('pt', 37.9), ('ro', 15.0), ('gl', 5.8)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 confusions for gbr:\n",
      "ET: [('en', 43.6), ('mk', 9.5), ('cy', 9.2)]\n",
      "PS: [('en', 37.8), ('cy', 18.5), ('la', 13.8)]\n",
      "ET+PS: [('en', 41.0), ('cy', 18.2), ('ab', 8.8)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 confusions for usg:\n",
      "ET: [('en', 39.1), ('fo', 10.9), ('mk', 7.6)]\n",
      "PS: [('en', 36.7), ('la', 17.4), ('ab', 6.2)]\n",
      "ET+PS: [('en', 43.8), ('fo', 7.1), ('ab', 6.2)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 confusions for car:\n",
      "ET: [('es', 28.9), ('mk', 10.6), ('fo', 8.2)]\n",
      "PS: [('la', 17.8), ('gl', 16.4), ('es', 8.9)]\n",
      "ET+PS: [('es', 26.6), ('gl', 8.1), ('ab', 6.2)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 confusions for eur:\n",
      "ET: [('ca', 22.9), ('es', 14.0), ('gl', 13.9)]\n",
      "PS: [('gl', 17.7), ('es', 14.0), ('la', 10.6)]\n",
      "ET+PS: [('es', 23.0), ('gl', 18.3), ('el', 7.8)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 confusions for lac:\n",
      "ET: [('es', 40.3), ('gl', 6.2), ('fo', 4.6)]\n",
      "PS: [('gl', 19.5), ('es', 15.1), ('la', 12.4)]\n",
      "ET+PS: [('es', 38.0), ('gl', 7.8), ('el', 4.4)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 confusions for cmn:\n",
      "ET: [('zh', 77.1), ('nn', 5.3), ('fo', 3.1)]\n",
      "PS: [('zh', 50.9), ('la', 14.1), ('vi', 7.3)]\n",
      "ET+PS: [('zh', 70.0), ('la', 8.3), ('vi', 3.9)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 confusions for nan:\n",
      "ET: [('zh', 23.5), ('vi', 10.5), ('fo', 9.3)]\n",
      "PS: [('la', 11.7), ('vi', 10.9), ('mi', 10.8)]\n",
      "ET+PS: [('vi', 18.4), ('zh', 16.1), ('th', 16.0)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 confusions for acm:\n",
      "ET: [('ar', 42.4), ('nn', 9.8), ('mk', 8.3)]\n",
      "PS: [('ar', 22.2), ('la', 19.8), ('ab', 8.3)]\n",
      "ET+PS: [('ar', 43.8), ('ab', 8.3), ('nn', 6.2)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 confusions for apc:\n",
      "ET: [('ar', 44.3), ('mk', 13.8), ('fo', 8.6)]\n",
      "PS: [('ar', 22.5), ('la', 15.9), ('sd', 10.1)]\n",
      "ET+PS: [('ar', 46.9), ('nn', 5.7), ('ab', 4.3)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 confusions for ary:\n",
      "ET: [('ar', 45.4), ('mk', 13.5), ('so', 4.0)]\n",
      "PS: [('ar', 18.0), ('la', 10.2), ('sd', 7.1)]\n",
      "ET+PS: [('ar', 45.4), ('so', 6.4), ('su', 3.7)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 confusions for arz:\n",
      "ET: [('ar', 54.1), ('fo', 16.6), ('nn', 5.5)]\n",
      "PS: [('la', 19.3), ('ar', 13.7), ('so', 6.6)]\n",
      "ET+PS: [('ar', 45.0), ('nn', 9.0), ('fo', 8.3)]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for accent in et_top_confusions:\n",
    "    print(f\"Top 3 confusions for {accent}:\")\n",
    "    et_list = [(k, v) for k, v in et_top_confusions[accent].items()]\n",
    "    ps_list = [(k, v) for k, v in ps_top_confusions[accent].items()]\n",
    "    etps_list = [(k, v) for k, v in etps_top_confusions[accent].items()]\n",
    "    print(f\"ET: {et_list}\")\n",
    "    print(f\"PS: {ps_list}\")\n",
    "    print(f\"ET+PS: {etps_list}\")\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accent_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
