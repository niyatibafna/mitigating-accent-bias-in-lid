{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.ones(1).cuda()\n",
    "import os, sys\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import re\n",
    "# Log to wandb\n",
    "import wandb\n",
    "import logging\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "sys.path.append(\"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/lid_with_acoustics-phoneseq\")\n",
    "from encode_and_transcribe_dataset import main as load_or_compute_encode_and_transcribe_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ab_transcriptions.jsonl\n",
      "Loading ar_transcriptions.jsonl\n",
      "Loading az_transcriptions.jsonl\n",
      "Loading am_transcriptions.jsonl\n",
      "Loading ba_transcriptions.jsonl\n",
      "Loading af_transcriptions.jsonl\n",
      "Loading bg_transcriptions.jsonl\n",
      "Loading br_transcriptions.jsonl\n",
      "Loading bn_transcriptions.jsonl\n",
      "Loading ceb_transcriptions.jsonl\n",
      "Loading bo_transcriptions.jsonl\n",
      "Loading be_transcriptions.jsonl\n",
      "Loading ca_transcriptions.jsonl\n",
      "Loading bs_transcriptions.jsonl\n",
      "Loading da_transcriptions.jsonl\n",
      "Loading cs_transcriptions.jsonl\n",
      "Loading eo_transcriptions.jsonl\n",
      "Loading cy_transcriptions.jsonl\n",
      "Loading de_transcriptions.jsonl\n",
      "Loading en_transcriptions.jsonl\n",
      "Loading et_transcriptions.jsonl\n",
      "Loading el_transcriptions.jsonl\n",
      "Loading eu_transcriptions.jsonl\n",
      "Loading es_transcriptions.jsonl\n",
      "Loading gn_transcriptions.jsonl\n",
      "Loading gv_transcriptions.jsonl\n",
      "Loading fi_transcriptions.jsonl\n",
      "Loading haw_transcriptions.jsonl\n",
      "Loading fa_transcriptions.jsonl\n",
      "Loading gu_transcriptions.jsonl\n",
      "Loading fo_transcriptions.jsonl\n",
      "Loading ia_transcriptions.jsonl\n",
      "Loading fr_transcriptions.jsonl\n",
      "Loading id_transcriptions.jsonl\n",
      "Loading it_transcriptions.jsonl\n",
      "Loading is_transcriptions.jsonl\n",
      "Loading hr_transcriptions.jsonl\n",
      "Loading ht_transcriptions.jsonl\n",
      "Loading jw_transcriptions.jsonl\n",
      "Loading ja_transcriptions.jsonl\n",
      "Loading km_transcriptions.jsonl\n",
      "Loading kn_transcriptions.jsonl\n",
      "Loading kk_transcriptions.jsonl\n",
      "Loading ka_transcriptions.jsonl\n",
      "Loading la_transcriptions.jsonl\n",
      "Loading ko_transcriptions.jsonl\n",
      "Loading lo_transcriptions.jsonl\n",
      "Loading lb_transcriptions.jsonl\n",
      "Loading mi_transcriptions.jsonl\n",
      "Loading ln_transcriptions.jsonl\n",
      "Loading lv_transcriptions.jsonl\n",
      "Loading lt_transcriptions.jsonl\n",
      "Loading ml_transcriptions.jsonl\n",
      "Loading mn_transcriptions.jsonl\n",
      "Loading mk_transcriptions.jsonl\n",
      "Loading mg_transcriptions.jsonl\n",
      "Loading mr_transcriptions.jsonl\n",
      "Loading ms_transcriptions.jsonl\n",
      "Loading mt_transcriptions.jsonl\n",
      "Loading my_transcriptions.jsonl\n",
      "Loading nl_transcriptions.jsonl\n",
      "Loading oc_transcriptions.jsonl\n",
      "Loading ne_transcriptions.jsonl\n",
      "Loading nn_transcriptions.jsonl\n",
      "Loading pa_transcriptions.jsonl\n",
      "Loading ps_transcriptions.jsonl\n",
      "Loading sa_transcriptions.jsonl\n",
      "Loading sco_transcriptions.jsonl\n",
      "Loading pl_transcriptions.jsonl\n",
      "Loading no_transcriptions.jsonl\n",
      "Loading pt_transcriptions.jsonl\n",
      "Loading ro_transcriptions.jsonl\n",
      "Loading ru_transcriptions.jsonl\n",
      "Loading sn_transcriptions.jsonl\n",
      "Loading sk_transcriptions.jsonl\n",
      "Loading sd_transcriptions.jsonl\n",
      "Loading si_transcriptions.jsonl\n",
      "Loading sr_transcriptions.jsonl\n",
      "Loading sv_transcriptions.jsonl\n",
      "Loading sq_transcriptions.jsonl\n",
      "Loading su_transcriptions.jsonl\n",
      "Loading sl_transcriptions.jsonl\n",
      "Loading so_transcriptions.jsonl\n",
      "Loading ta_transcriptions.jsonl\n",
      "Loading sw_transcriptions.jsonl\n",
      "Loading te_transcriptions.jsonl\n",
      "Loading tg_transcriptions.jsonl\n",
      "Loading th_transcriptions.jsonl\n",
      "Loading tr_transcriptions.jsonl\n",
      "Loading tk_transcriptions.jsonl\n",
      "Loading ur_transcriptions.jsonl\n",
      "Loading tl_transcriptions.jsonl\n",
      "Loading uk_transcriptions.jsonl\n",
      "Loading war_transcriptions.jsonl\n",
      "Loading uz_transcriptions.jsonl\n",
      "Loading yi_transcriptions.jsonl\n",
      "Loading tt_transcriptions.jsonl\n",
      "Loading zh_transcriptions.jsonl\n",
      "Loading vi_transcriptions.jsonl\n",
      "Loading yo_transcriptions.jsonl\n",
      "Loading as_transcriptions.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97dda5ab097a40ebbfbb07a7fdc8f310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hy_transcriptions.jsonl\n",
      "Loading gl_transcriptions.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59992d90d3e14888a435dbea056e6b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hu_transcriptions.jsonl\n",
      "Loading hi_transcriptions.jsonl\n",
      "Loading ha_transcriptions.jsonl\n",
      "Loading iw_transcriptions.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3430a760c214003b86adfe05357a613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "outdir = \"/exp/nbafna/projects/mitigating-accent-bias-in-lid/reps_and_phoneseqs/vl107/ecapa-tdnn_wav2vec2-xlsr-53-espeak-cv-ft\"\n",
    "files = os.listdir(outdir)\n",
    "files = [f for f in files if f.endswith(\".jsonl\")]\n",
    "\n",
    "# Load all the files as HF dataset\n",
    "all_datasets = []\n",
    "for f in files:\n",
    "    print(f\"Loading {f}\")\n",
    "    lang_dataset = datasets.load_dataset(\"json\", data_files=os.path.join(outdir, f))\n",
    "    all_datasets.append(lang_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "all_datasets = [d[\"train\"] for d in all_datasets]\n",
    "dataset = concatenate_datasets(all_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2645466, 2645466]\n"
     ]
    }
   ],
   "source": [
    "print([sum([len(d) for d in all_datasets]), len(dataset)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accent_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
