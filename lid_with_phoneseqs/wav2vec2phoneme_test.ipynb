{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-xlsr-53-espeak-cv-ft were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-xlsr-53-espeak-cv-ft and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/hltcoe/nbafna/.conda/envs/accent_bias/lib/python3.12/site-packages/datasets/load.py:1486: FutureWarning: The repository for patrickvonplaten/librispeech_asr_dummy contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/patrickvonplaten/librispeech_asr_dummy\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    " \n",
    "# load model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-xlsr-53-espeak-cv-ft\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-xlsr-53-espeak-cv-ft\")\n",
    "    \n",
    "# load dummy dataset and read soundfiles\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ð ə b ʌ z ɚ z w ɚ t ɹ ɪ ɡ ɚ d ɪ z m ʌ s ʊ l z ɪ n t ə k ə m p l iː t ɹ iː l æ k s eɪ ʃ ə n']\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "input_values = processor(ds[6][\"audio\"][\"array\"], return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "\n",
    "# retrieve logits\n",
    "with torch.no_grad():\n",
    "  logits = model(input_values).logits\n",
    "\n",
    "# take argmax and decode\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)\n",
    "print(transcription)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: THE BUZZER'S WHIRR TRIGGERED HIS MUSCLES INTO COMPLETE RELAXATION\n",
      "78880\n"
     ]
    }
   ],
   "source": [
    "print(f\"Text: {ds[6]['text']}\")\n",
    "print(len(ds[6][\"audio\"][\"array\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 76 audio files\n",
      "Recorded 122 speakers\n",
      "Loaded 28 segments\n",
      "Sample: {'signal': array([-0.00042685, -0.00044512, -0.00030128, ...,  0.02896704,\n",
      "        0.01170549, -0.03144089], dtype=float32), 'lang': 'scottish', 'transcript': \"RIGHT AND NOW I THINK WE JUST HAVE TO CONVERSE FOR FIFTEEN MINUTES UM LET'S START WITH THE FIRST ONE WHEN YOU WERE A KID WHAT KINDS OF GAMES DID YOU PLAY IS THERE ONE YOU REMEMBER WELL LIKE YOU CAN GO FIRST 'CAUSE YOU HAD A GAME\"}\n",
      "Languages: {'scottish'}\n"
     ]
    }
   ],
   "source": [
    "import os, sys, csv, json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pandas import DataFrame as df\n",
    "import torch\n",
    "import torchaudio\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# wav_file = \"/exp/nbafna/data/l2_arctic/l2arctic_release_v5/ABA/wav/arctic_a0001.wav\"\n",
    "\n",
    "# Test on EdAcc dataset\n",
    "def stm_reader(stm_path):\n",
    "    stm_data = []\n",
    "    with open(stm_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line_data = {}\n",
    "            parts = line.split()\n",
    "            line_data[\"audio_file\"] = parts[0]\n",
    "            line_data[\"channel\"] = parts[1]\n",
    "            line_data[\"speaker\"] = parts[2]\n",
    "            line_data[\"start_time\"] = float(parts[3])\n",
    "            line_data[\"end_time\"] = float(parts[4])\n",
    "            line_data[\"label\"] = parts[5]\n",
    "            line_data[\"transcript\"] = \" \".join(parts[6:])\n",
    "            stm_data.append(line_data)\n",
    "    return stm_data\n",
    "\n",
    "def load_edacc(num_samples = None):\n",
    "    test_stm_path = \"/exp/nbafna/data/edacc/edacc_v1.0/test/stm\"\n",
    "    dev_stm_path = \"/exp/nbafna/data/edacc/edacc_v1.0/dev/stm\"\n",
    "    data_path = \"/exp/nbafna/data/edacc/edacc_v1.0/data\"\n",
    "\n",
    "    audio_files = {}\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=32000, new_freq=16000)\n",
    "    for audio_file in os.listdir(data_path):\n",
    "        audio_files[audio_file[:-4]], sr = torchaudio.load(os.path.join(data_path, audio_file))\n",
    "        audio_files[audio_file[:-4]] = resampler(audio_files[audio_file[:-4]])\n",
    "        # audio_files[audio_file[:-4]] = language_id.load_audio(os.path.join(data_path, audio_file))\n",
    "        sr = 16000 # This is the sampling rate for the language_id model, audio is normalized when loaded\n",
    "    print(f\"Loaded {len(audio_files)} audio files\")\n",
    "\n",
    "    speaker2lang = {}\n",
    "    # linguistic_background = \"/exp/nbafna/data/edacc/edacc_v1.0/linguistic_background.csv\"\n",
    "    # with open(linguistic_background, \"r\") as f:\n",
    "    #     reader = csv.reader(f)\n",
    "    #     for row in reader:\n",
    "    #         speaker2lang[row[1]] = row[12]\n",
    "    participant2accent_path = \"/exp/nbafna/data/edacc/edacc_v1.0/participant2accent.json\"\n",
    "    with open(participant2accent_path, \"r\") as f:\n",
    "        speaker2lang = json.load(f)\n",
    "    print(f\"Recorded {len(speaker2lang)} speakers\")\n",
    "\n",
    "    all_data = []\n",
    "    stm_data = stm_reader(test_stm_path) + stm_reader(dev_stm_path)\n",
    "    for line in stm_data[:100]:\n",
    "        audio_file = line[\"audio_file\"]\n",
    "        signal = audio_files[audio_file]\n",
    "        signal = signal.squeeze().numpy()\n",
    "        segment = signal[int(line[\"start_time\"]*sr):int(line[\"end_time\"]*sr)]\n",
    "        transcript = line[\"transcript\"]\n",
    "\n",
    "        if \"IGNORE_TIME_SEGMENT_IN_SCORING\" in transcript:\n",
    "            continue\n",
    "        # Filter out signals with less than 6 seconds\n",
    "        if segment.shape[0] < 6*16000:\n",
    "            continue\n",
    "        # Chunk into uniform windows of K seconds\n",
    "        K = 6\n",
    "        for i in range(0, len(segment), K*16000):\n",
    "            if i+K*16000 > len(segment):\n",
    "                break\n",
    "            all_data.append({\"signal\": segment[i:i+K*16000], \\\n",
    "                             \"lang\": speaker2lang[line[\"speaker\"]],\\\n",
    "                                \"transcript\": transcript})\n",
    "\n",
    "        # segment = segment[:10*16000]\n",
    "        # lang = speaker2lang[line[\"speaker\"]]\n",
    "        # all_data.append({\"signal\": segment, \"lang\": lang})\n",
    "\n",
    "        # if len(all_data)%10 == 0:\n",
    "        #     print(f\"Printing out sample\")\n",
    "        #     print(f\"Lang: {lang}\")\n",
    "        #     print(f\"Speaker: {line['speaker']}\")\n",
    "        #     print(f\"Start and end times: {line['start_time']}, {line['end_time']}\")\n",
    "        #     print(f\"Expected length: {int((line['end_time']-line['start_time'])*sr)}\")\n",
    "        #     print(f\"Length of audio: {segment.shape}\")\n",
    "    \n",
    "    print(f\"Loaded {len(all_data)} segments\")\n",
    "    print(f\"Sample: {all_data[0]}\")\n",
    "    all_langs = set([f[\"lang\"] for f in all_data])\n",
    "    print(f\"Languages: {all_langs}\")\n",
    "\n",
    "    if num_samples is not None:\n",
    "        all_data = random.sample(all_data, min(len(all_data), num_samples))\n",
    "    all_data = {\"signal\": [f[\"signal\"] for f in all_data], \\\n",
    "                \"lang\": [f[\"lang\"] for f in all_data],\\\n",
    "                    \"transcript\": [f[\"transcript\"] for f in all_data]}\n",
    "    \n",
    "    return Dataset.from_dict(all_data)\n",
    "\n",
    "                \n",
    "dataset = load_edacc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIGHT AND NOW I THINK WE JUST HAVE TO CONVERSE FOR FIFTEEN MINUTES UM LET'S START WITH THE FIRST ONE WHEN YOU WERE A KID WHAT KINDS OF GAMES DID YOU PLAY IS THERE ONE YOU REMEMBER WELL LIKE YOU CAN GO FIRST 'CAUSE YOU HAD A GAME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ɹ aɪ t æ n d n ɑː aɪ θ ɪ ŋ k w iː dʒ ʌ s t h æ f t ə k ə n v ɚ s t ɚ f ɪ f t iː n m ɪ n ɪ t ts m ɐ s']\n",
      "\n",
      "\n",
      "RIGHT AND NOW I THINK WE JUST HAVE TO CONVERSE FOR FIFTEEN MINUTES UM LET'S START WITH THE FIRST ONE WHEN YOU WERE A KID WHAT KINDS OF GAMES DID YOU PLAY IS THERE ONE YOU REMEMBER WELL LIKE YOU CAN GO FIRST 'CAUSE YOU HAD A GAME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s ɑː w ʌ z f ɚ s t w ʌ n w ɛ n uː ɹ ɪ k ɪ d w ɔ t k aɪ m z ʌ v ɡ eɪ m z d ɪ d j uː p l eɪ ɪ z ð ə w ʌ n j uː ɹ m ɛ m b ɚ w ɛ l aɪ j ɪ ŋ ɡ oʊ f ɚ']\n",
      "\n",
      "\n",
      "WHICH IS JUST THE WHICH IS JUST A UH BASICALLY YOU HAVE TWO ENDS OF A PITCH AND YOUR GOAL'S TO REACH THE OTHER END OF THE PITCH WITHOUT BEING TAGGED BY SOMEONE IN THE MIDDLE AND NO RULES APPLY PEOPLE WERE BEATEN UP BLOOD EVERYWHERE OH GOOD TIMES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w ɪ tʃ ɪ z dʒ ʌ s t ə æ b eɪ s k ʊ j h æ v t uː ɛ n z ʌ v ɐ p ɪ tʃ æ n d j uː ɡ oː l z s t ɹ uː v iː tʃ ð iː ʌ ð ɚ ɹ ɛ n t ə ð ə p ɪ']\n",
      "\n",
      "\n",
      "WHICH IS JUST THE WHICH IS JUST A UH BASICALLY YOU HAVE TWO ENDS OF A PITCH AND YOUR GOAL'S TO REACH THE OTHER END OF THE PITCH WITHOUT BEING TAGGED BY SOMEONE IN THE MIDDLE AND NO RULES APPLY PEOPLE WERE BEATEN UP BLOOD EVERYWHERE OH GOOD TIMES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dʒ w ɪ ð aʊ t b iː ɪ ŋ t æ k t b aɪ s ʌ m w ʌ n ɪ n ð ə m ɪ d ʊ æ n d n oʊ ɹ uː l z ʌ p l aɪ p iː p əl w ɚ']\n",
      "\n",
      "\n",
      "THAT WOULD NOT GO WELL UM SIMILAR TO THE SIMILARLY TO THAT I PLAYED LOTS OF SHARKS AND FISHES IN UM LIKE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h aɪ w ʊ l n ɔ t ɡ oː w ɛ l æ m s ɪ m ɪ l t ɪ ɪ t s ɪ m ɪ ə l i t ə ð æ t ɐ p d l ʌ s ə s ʃ ɑː k s ə n f ɪ ʃ ɪ z']\n",
      "\n",
      "\n",
      "WE'D UH THE IDEA IT'S ESSENTIALLY THE SAME AS BULLDOG YOU HAVE TO TRY AND RUN TO THE END OF THE FIELD THERE'S ONE PERSON WHO'S THIS SHARK OR MAYBE TWO PEOPLE AND THEY CAN MOVE ANY DIRECTION AND IF THEY TAKE YOU YOU BECOME SEAWEED AND YOU CAN'T MOVE YOUR FEET BUT YOU CAN LIKE LEAN OUT TO CATCH PEOPLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ð ɪ aɪ d iː ɾ ɪ z ɪ z ɪ s ɛ n ʃ l i ð ə s eɪ m ə z b ʊ ɡ oʊ k æ t ə d ɹ aɪ n m ə n d t ɪ n ð ə f iː l d ð ɛ ɹ ɪ z w ʌ n p ɚ s ə n h uː z ð ɪ ʃ t']\n",
      "\n",
      "\n",
      "WE'D UH THE IDEA IT'S ESSENTIALLY THE SAME AS BULLDOG YOU HAVE TO TRY AND RUN TO THE END OF THE FIELD THERE'S ONE PERSON WHO'S THIS SHARK OR MAYBE TWO PEOPLE AND THEY CAN MOVE ANY DIRECTION AND IF THEY TAKE YOU YOU BECOME SEAWEED AND YOU CAN'T MOVE YOUR FEET BUT YOU CAN LIKE LEAN OUT TO CATCH PEOPLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ʃ ɑː k k ɚ m ɪ v iː t uː p iː p əl æ n ð eɪ k ə n m uː v ɛ n i d ə ɹ ɹ ɛ k ʃ ə n æ n ɪ f ð t eɪ k j uː j uː b ɪ k ʌ m s iː w iː d æ n d j uː k']\n",
      "\n",
      "\n",
      "AND THEN IF THE GAME WAS DRAGGING ON THE SEAWEED WOULD BECOME CRABS SO THEY CAN MOVE SIDE TO SIDE BUT NOT FORWARDS AND BACKWARDS SO IT WAS REALLY IT WAS QUITE QUITE A LITTLE <OVERLAP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['æ n d ð ɛ n n ɪ f ð ə ɡ eɪ m w ʌ z d ɹ æ ɡ ə n ɔ n ð ə s iː w iː d ə b ɪ k ʌ m k ɹ æ b z s l eɪ k ə d m uː v s aɪ d t ə s']\n",
      "\n",
      "\n",
      "IT WAS VERY FUN THOUGH I LOVED PLAYING IT I ALWAYS WOULD LAST TO THE LAST LIKE TWO OR THREE THAT'D BE SO GOOD UM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ɪ t w ʌ z v ɛ ɹ i f ʌ n n oʊ ɐ l ʌ v l ɪ ŋ h ɛ ɾ oː w ɪ z b oʊ t l æ t ɪ l æ s t l aɪ k t uː ɚ t ɹ i ɛ v i']\n",
      "\n",
      "\n",
      "WE DID A FEW TIMES WHERE IT WOULD BE LIKE UM LIKE A BIB YOU HAD TO PULL OUT SOMETIMES AS WELL LIKE YOU TOOK THE BIB IN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d ɪ d ə f j uː t aɪ m z w ɚ ɹ ɪ ɾ ʊ d b iː l aɪ k ɐ l aɪ k ɐ b ɪ b j a t ə p ʊ l aʊ t s ʌ m t aɪ m z ə z w ɛ l']\n",
      "\n",
      "\n",
      "YOUR SHORTS AND YOU HAD TO LIKE YANK IT OUT IN TIME FOR IT TO COUNT AS A CATCH AND I THINK THAT WAS WHEN WE WERE PLAYING TOUCH RUGBY SO WE COULD PRACTICE YOU KNOW TOUCH TACKLES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j ɚ ʃ oː t s æ n d h j iː h æ z l aɪ k j æ ŋ k ɪ aʊ ɪ n t aɪ m f oʊ ɹ ɪ t t ə k aʊ n ɪ z ə k æ tʃ n aɪ ð æ w ʌ z h uː m uː']\n",
      "\n",
      "\n",
      "AND THEN THERE WAS LIKE A PIG STYLE WHERE YOU LIKE CHASE THE PERSON WITH THE BALL AND JUST THROW IT AT THEM WHICH LIKE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['æ n ð ɛ n ð ɛ w ʌ z l aɪ k ɐ t ɪ ɡ s t aɪ l w eɪ j uː l aɪ k tʃ eɪ s ə p ɚ s ə n w ɪ ð ð ə b ɑː l æ n dʒ ʌ s t r oː']\n",
      "\n",
      "\n",
      "I I SUPPOSE IF PEOPLE WERE JUST REALLY BAD AT THROWING BECAUSE THEY WERE REALLY QUITE YOUNG I MEAN WE WERE ALL REALLY YOUNG BUT IT'S STILL VERY WEIRD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aɪ s aɪ s ə p oʊ z ð ə p iː p oʊ d ɪ s ɹ ɪ l i b aɪ ɾ æ ð ɹ ɪ ŋ k s ɪ ɹ ɪ l i k w aɪ t ɪ j ʌ ŋ ɚ ɹ ɪ l i j ʌ ŋ b ʌ t ɪ t']\n",
      "\n",
      "\n",
      "YEAH BIG BIG HALL FOR THE SIZE I REMEMBER GOING BACK THERE WHEN I WAS A LOT OLDER AND I REMEMBER SEEING THE BASKETBALL HOOPS IN THE HALL AND I COULD LIKE DUNK ON THEM WHICH WAS SO WEIRD BECAUSE BASKETBALL HOOPS ARE SUPPOSED TO BE LIKE TEN FEET TALL AND AT THE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j ɛ b ɪ ɡ b ɪ ɡ h ɔ l ɔ f ɚ ð ə s aɪ z aɪ m ɛ m b ɚ ɡ oː ɪ ŋ b æ k ð ɛ ɹ w ɛ n aɪ w ʌ z ɐ l ɑː t oː l d ɚ']\n",
      "\n",
      "\n",
      "YEAH BIG BIG HALL FOR THE SIZE I REMEMBER GOING BACK THERE WHEN I WAS A LOT OLDER AND I REMEMBER SEEING THE BASKETBALL HOOPS IN THE HALL AND I COULD LIKE DUNK ON THEM WHICH WAS SO WEIRD BECAUSE BASKETBALL HOOPS ARE SUPPOSED TO BE LIKE TEN FEET TALL AND AT THE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['æ n d aɪ n ɛ v ɚ s iː n ð ə b æ s k w oː l l h y p s ɪ n ð ə h ɑː l æ n aɪ k ʊ d l eɪ k d ɔ ŋ k ɔ n ð ɛ m w ɪ tʃ ɪ z']\n",
      "\n",
      "\n",
      "PRIMARY SCHOOL IT WASN'T EVEN SEVEN FEET SO IT WAS VERY FUN TO GO BACK THERE THEN MESS ABOUT THEREAFTER I DID SOME UM COACHING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p aɪ m ɪ s k uː l ɪ t w ʌ z ə n t iː v ə n s ɛ v ə n f iː t s ɪ t w ʌ z v ɛ ɹ i f ɔ n t ɪ ɡ oː b æ k ð ɛ']\n",
      "\n",
      "\n",
      "THE IDEA IS THERE'S THIS MYSTERY GANG THESE FIVE PEOPLE AND ONE TALKING DOG AND THEY'D GO AND SOLVE MYSTERIES AND THERE'D BE LIKE SOME PERSON DRESSED UP AS A MONSTER OR GHOST TERRORIZING SOME NEIGHBORHOOD OR SOMETHING AND THEY'D UM TRY AND FIND OUT WHO IT WAS THEY'D GET SOMEONE SOMEONE WOULD CALL THEM IN LIKE HELP WE NEED TO SOLVE THIS AND THEY'D BE LIKE OKAY WE'RE HERE TO HELP AND AT THE END THEY'D ALWAYS REVEAL THE PERSON THEY HAD TO CATCH THEM IN A BIG ELABORATE PLAN TAKE THEIR MASK OFF AND IT WOULD BE ONE OF THE PEOPLE THAT HAD CALLED THEM FOR HELP SOMETHING LIKE THAT IT WAS ALWAYS QUITE FUNNY AND IT WAS ALWAYS QUITE SILLY IT HAD A VERY SLAP STICK WAY OF RUNNING AND EATING AS WELL IT WAS A VERY ENJOYABLE TV SHOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eː z ð ɛ z z ð ɪ s k w ʌ ə ŋ k oː m ɪ s t ɚ ɹ i ɡ æ n d iː z f aɪ v p iː p ʊ æ n d w ʌ n']\n",
      "\n",
      "\n",
      "THE IDEA IS THERE'S THIS MYSTERY GANG THESE FIVE PEOPLE AND ONE TALKING DOG AND THEY'D GO AND SOLVE MYSTERIES AND THERE'D BE LIKE SOME PERSON DRESSED UP AS A MONSTER OR GHOST TERRORIZING SOME NEIGHBORHOOD OR SOMETHING AND THEY'D UM TRY AND FIND OUT WHO IT WAS THEY'D GET SOMEONE SOMEONE WOULD CALL THEM IN LIKE HELP WE NEED TO SOLVE THIS AND THEY'D BE LIKE OKAY WE'RE HERE TO HELP AND AT THE END THEY'D ALWAYS REVEAL THE PERSON THEY HAD TO CATCH THEM IN A BIG ELABORATE PLAN TAKE THEIR MASK OFF AND IT WOULD BE ONE OF THE PEOPLE THAT HAD CALLED THEM FOR HELP SOMETHING LIKE THAT IT WAS ALWAYS QUITE FUNNY AND IT WAS ALWAYS QUITE SILLY IT HAD A VERY SLAP STICK WAY OF RUNNING AND EATING AS WELL IT WAS A VERY ENJOYABLE TV SHOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t ɔ k ɪ ŋ d ɔ ɡ æ n ð eɪ d ɡ oː ə n d s ɔ l v m ɪ s t ɚ ɹ i z æ n d ɛ d b iː l aɪ k s']\n",
      "\n",
      "\n",
      "THE IDEA IS THERE'S THIS MYSTERY GANG THESE FIVE PEOPLE AND ONE TALKING DOG AND THEY'D GO AND SOLVE MYSTERIES AND THERE'D BE LIKE SOME PERSON DRESSED UP AS A MONSTER OR GHOST TERRORIZING SOME NEIGHBORHOOD OR SOMETHING AND THEY'D UM TRY AND FIND OUT WHO IT WAS THEY'D GET SOMEONE SOMEONE WOULD CALL THEM IN LIKE HELP WE NEED TO SOLVE THIS AND THEY'D BE LIKE OKAY WE'RE HERE TO HELP AND AT THE END THEY'D ALWAYS REVEAL THE PERSON THEY HAD TO CATCH THEM IN A BIG ELABORATE PLAN TAKE THEIR MASK OFF AND IT WOULD BE ONE OF THE PEOPLE THAT HAD CALLED THEM FOR HELP SOMETHING LIKE THAT IT WAS ALWAYS QUITE FUNNY AND IT WAS ALWAYS QUITE SILLY IT HAD A VERY SLAP STICK WAY OF RUNNING AND EATING AS WELL IT WAS A VERY ENJOYABLE TV SHOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ʌ m p ɚ s ə n d ɹ ɛ s t ʌ p ʌ z ɐ m ɔ n s t ɚ ɚ ɡ oʊ s t t ɛ ɹ ɚ ɹ aɪ z ɪ ŋ s ʌ m n eɪ b ɚ h ʊ d ɚ s ʌ m θ ɪ ŋ']\n",
      "\n",
      "\n",
      "THE IDEA IS THERE'S THIS MYSTERY GANG THESE FIVE PEOPLE AND ONE TALKING DOG AND THEY'D GO AND SOLVE MYSTERIES AND THERE'D BE LIKE SOME PERSON DRESSED UP AS A MONSTER OR GHOST TERRORIZING SOME NEIGHBORHOOD OR SOMETHING AND THEY'D UM TRY AND FIND OUT WHO IT WAS THEY'D GET SOMEONE SOMEONE WOULD CALL THEM IN LIKE HELP WE NEED TO SOLVE THIS AND THEY'D BE LIKE OKAY WE'RE HERE TO HELP AND AT THE END THEY'D ALWAYS REVEAL THE PERSON THEY HAD TO CATCH THEM IN A BIG ELABORATE PLAN TAKE THEIR MASK OFF AND IT WOULD BE ONE OF THE PEOPLE THAT HAD CALLED THEM FOR HELP SOMETHING LIKE THAT IT WAS ALWAYS QUITE FUNNY AND IT WAS ALWAYS QUITE SILLY IT HAD A VERY SLAP STICK WAY OF RUNNING AND EATING AS WELL IT WAS A VERY ENJOYABLE TV SHOW\n",
      "['æ n d ð eɪ d æ t aɪ n f aɪ d ɑː t h uː ɪ t w ɔ z ɪ t ɡ ɛ t s ʌ m w ʌ n t n t ə k ɑː l ɪ m ɪ n l aɪ k h æ l p n iː d z ɪ']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in dataset.select(range(20)):\n",
    "    if \"IGNORE_TIME_SEGMENT_IN_SCORING\" in data[\"transcript\"]:\n",
    "        continue\n",
    "    print(data[\"transcript\"])\n",
    "    input_values = processor(data[\"signal\"], return_tensors=\"pt\").input_values\n",
    "    logits = model(input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    print(transcription)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files...\n",
      "Loading common_voice_en_18779909.mp3...\n",
      "Loading common_voice_en_18645479.mp3...\n",
      "Loading common_voice_en_18717362.mp3...\n",
      "Loading common_voice_en_18754910.mp3...\n",
      "Loading common_voice_en_18838960.mp3...\n",
      "Loading common_voice_en_516474.mp3...\n",
      "Loading common_voice_en_18853644.mp3...\n",
      "Loading common_voice_en_127920.mp3...\n",
      "Loading common_voice_en_18403277.mp3...\n",
      "Loading common_voice_en_208920.mp3...\n",
      "Loading common_voice_en_609959.mp3...\n",
      "Loading common_voice_en_609955.mp3...\n",
      "Loading common_voice_en_609949.mp3...\n",
      "Loading common_voice_en_609943.mp3...\n",
      "Loading common_voice_en_609946.mp3...\n",
      "Loading common_voice_en_18852367.mp3...\n",
      "Loading common_voice_en_18717941.mp3...\n",
      "Loading common_voice_en_18720025.mp3...\n",
      "Loading common_voice_en_18411453.mp3...\n",
      "Loading common_voice_en_18488699.mp3...\n",
      "Loading common_voice_en_18672396.mp3...\n",
      "Loading common_voice_en_18834942.mp3...\n",
      "Loading common_voice_en_18482654.mp3...\n",
      "Loading common_voice_en_17719008.mp3...\n",
      "Loading common_voice_en_18910227.mp3...\n",
      "Loading common_voice_en_18658102.mp3...\n",
      "Loading common_voice_en_18680660.mp3...\n",
      "Loading common_voice_en_594321.mp3...\n",
      "Loading common_voice_en_18708222.mp3...\n",
      "Loading common_voice_en_18802019.mp3...\n",
      "Loading common_voice_en_18714571.mp3...\n",
      "Loading common_voice_en_18893522.mp3...\n",
      "Loading common_voice_en_18714977.mp3...\n",
      "Loading common_voice_en_141401.mp3...\n",
      "Loading common_voice_en_18906287.mp3...\n",
      "Loading common_voice_en_18691385.mp3...\n",
      "Loading common_voice_en_18685694.mp3...\n",
      "Loading common_voice_en_18697738.mp3...\n",
      "Loading common_voice_en_116623.mp3...\n",
      "Loading common_voice_en_18618512.mp3...\n",
      "Loading common_voice_en_18600103.mp3...\n",
      "Loading common_voice_en_18718429.mp3...\n",
      "Loading common_voice_en_18748199.mp3...\n",
      "Loading common_voice_en_18620836.mp3...\n",
      "Loading common_voice_en_18718408.mp3...\n",
      "Loading common_voice_en_18712948.mp3...\n",
      "Loading common_voice_en_96748.mp3...\n",
      "Loading common_voice_en_18713075.mp3...\n",
      "Loading common_voice_en_18713071.mp3...\n",
      "Loading common_voice_en_18712970.mp3...\n",
      "Loading common_voice_en_18918968.mp3...\n",
      "Loading common_voice_en_18918925.mp3...\n",
      "Loading common_voice_en_18715033.mp3...\n",
      "Loading common_voice_en_18922257.mp3...\n",
      "Loading common_voice_en_18841332.mp3...\n",
      "Loading common_voice_en_195598.mp3...\n",
      "Loading common_voice_en_676553.mp3...\n",
      "Loading common_voice_en_195590.mp3...\n",
      "Loading common_voice_en_18785178.mp3...\n",
      "Loading common_voice_en_18515942.mp3...\n",
      "Loading common_voice_en_18785422.mp3...\n",
      "Loading common_voice_en_18722272.mp3...\n",
      "Loading common_voice_en_18785339.mp3...\n",
      "Loading common_voice_en_43472.mp3...\n",
      "Loading common_voice_en_43516.mp3...\n",
      "Loading common_voice_en_18684063.mp3...\n",
      "Loading common_voice_en_43519.mp3...\n",
      "Loading common_voice_en_630330.mp3...\n"
     ]
    }
   ],
   "source": [
    "# TEST ON CV\n",
    "\n",
    "def load_cv(per_accent = None):\n",
    "    files = {}\n",
    "    accents = {'indian', 'singapore', 'scotland', 'us', 'canada', 'wales', 'england', 'philippines', 'african', 'newzealand', 'ireland', 'malaysia', 'hongkong', 'australia'}\n",
    "    for line in open(\"/export/common/data/corpora/ASR/commonvoice/en/train.tsv\"):\n",
    "        if len(line.strip().split(\"\\t\")) < 8:\n",
    "            continue\n",
    "        audio, transcript, accent = line.strip().split(\"\\t\")[1], line.strip().split(\"\\t\")[2], line.strip().split(\"\\t\")[7]\n",
    "        if accent not in accents:\n",
    "            continue\n",
    "        if accent not in files:\n",
    "            files[accent] = []\n",
    "        files[accent].append((audio, transcript))\n",
    "\n",
    "    for accent in accents:\n",
    "        if accent not in files:\n",
    "            continue\n",
    "        random.shuffle(files[accent])\n",
    "        files[accent] = files[accent][:per_accent]\n",
    "        \n",
    "    # print(files)\n",
    "    print(\"Loading audio files...\")\n",
    "    data = []\n",
    "    resampler = torchaudio.transforms.Resample(48000, 16000)\n",
    "    clips_folder = \"/export/common/data/corpora/ASR/commonvoice/en/clips/\"\n",
    "    for accent in files:\n",
    "        for (audio, transcript) in files[accent]:\n",
    "            print(f\"Loading {audio}...\")\n",
    "            signal, sr = torchaudio.load(os.path.join(clips_folder, audio))\n",
    "            if sr != 16000:\n",
    "                # Resample\n",
    "                signal = resampler(signal)\n",
    "\n",
    "            signal = signal.squeeze().numpy()\n",
    "            data.append({\"signal\": signal, \\\n",
    "                             \"lang\": accent, \\\n",
    "                                \"filename\": os.path.join(clips_folder, audio),\\\n",
    "                                    \"transcript\": transcript})\n",
    "            \n",
    "            # signal = language_id.load_audio(os.path.join(clips_folder, audio))\n",
    "            # K = signal.shape[0] // 16000\n",
    "            # if signal.shape[0] < 10*16000:\n",
    "            #     print(f\"Signal too short: {signal.shape[0]}\")\n",
    "            #     continue\n",
    "            \n",
    "            # for i in range(0, len(signal), K*16000):\n",
    "            #     if i+K*16000 > len(signal):\n",
    "            #         break\n",
    "            #     data.append({\"signal\": signal[i:i+K*16000], \\\n",
    "            #                  \"lang\": accent, \\\n",
    "            #                     \"filename\": os.path.join(clips_folder, audio),\\\n",
    "            #                         \"transcript\": transcript})\n",
    "            \n",
    "\n",
    "    data = {\"signal\": [f[\"signal\"] for f in data], \\\n",
    "            \"lang\": [f[\"lang\"] for f in data], \\\n",
    "                \"filename\": [f[\"filename\"] for f in data],\n",
    "                \"transcript\": [f[\"transcript\"] for f in data]}\n",
    "    return Dataset.from_dict(data)\n",
    "        \n",
    "dataset = load_cv(per_accent = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: Many of the stalls have passed from one generation to the other.\n",
      "/export/common/data/corpora/ASR/commonvoice/en/clips/common_voice_en_18717362.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m ɛ n i ʌ v ð ə s t ɑː l z h ɛ v p æ s t f ʌ m w ʌ n dʒ ɛ n ɚ ɹ eɪ ʃ ə n t uː ð i ʌ ð ɚ']\n",
      "\n",
      "\n",
      "Truth: However, research shows that this crop has the potential to increase in yield.\n",
      "/export/common/data/corpora/ASR/commonvoice/en/clips/common_voice_en_18713075.mp3\n",
      "['h aʊ ɛ v ɚ ɹ ɪ s ɚ tʃ ʃ oʊ z ð ɐ t ð ɪ s k ɹ ɑː p h ɪ z ð ə p ə t ɛ n ʃ ə l t ʊ ɪ n k ɹ iː s ɪ n j iː l d']\n",
      "\n",
      "\n",
      "Truth: An old man plays guitar in front of a red bucket filled with money.\n",
      "/export/common/data/corpora/ASR/commonvoice/en/clips/common_voice_en_609946.mp3\n",
      "['ɐ n oʊ l d d m æ n p l eɪ z ɡ ɪ t ɑː ɪ n f ɚ n t ʌ v ɐ ɹ ɛ d b æ k ə t f ɪ l d w ɪ ð m ʌ n i']\n",
      "\n",
      "\n",
      "Truth: Even the women knew how to be silent.\n",
      "/export/common/data/corpora/ASR/commonvoice/en/clips/common_voice_en_17719008.mp3\n",
      "['iː v ə n ð ə w ʊ m ə n n uː h aʊ t ʊ b iː s aɪ l ə n t']\n",
      "\n",
      "\n",
      "Truth: \"He also appears in the second O'Keefe family novel, \"\"Dragons in the Waters\"\".\"\n",
      "/export/common/data/corpora/ASR/commonvoice/en/clips/common_voice_en_18853644.mp3\n",
      "['h iː ɐ p ɪ z ɪ n ð ə s ɛ k ə n d oʊ k iː θ f æ m ə l i n ɔ v ɚ d ɹ æ ɡ ə n z ɪ n ð ə w oː t ɚ z']\n",
      "\n",
      "\n",
      "Truth: In the United States, the album debuted at No.\n",
      "/export/common/data/corpora/ASR/commonvoice/en/clips/common_voice_en_18691385.mp3\n",
      "['ɪ n ð ɪ j uː n aɪ ɾ ɪ d s t eɪ t s ð ɪ æ l b ə m d eɪ b j uː d æ t n ʌ m b ɚ']\n",
      "\n",
      "\n",
      "Truth: So she called softly after it, ‘Mouse dear!’\n",
      "/export/common/data/corpora/ASR/commonvoice/en/clips/common_voice_en_18403277.mp3\n",
      "['s oʊ ʃ iː k ɔ l d s ɔ f t l i a f t ɚ ɹ ɪ t m aʊ s d eː']\n",
      "\n",
      "\n",
      "Truth: A man is getting ready to hit a tennis ball.\n",
      "/export/common/data/corpora/ASR/commonvoice/en/clips/common_voice_en_43472.mp3\n",
      "['ɐ m æ n ɪ z ɡ ɛ t ɪ ŋ ɹ ɛ d i t ʊ tʃ iː t ɐ t ɛ n eɪ z b oː']\n",
      "\n",
      "\n",
      "Truth: Two women stand outside with a young girl.\n",
      "/export/common/data/corpora/ASR/commonvoice/en/clips/common_voice_en_141401.mp3\n",
      "['t uː w ɪ m ə n s t æ n d ɑː t s aɪ d w ɪ ð ɐ j ʌ ŋ ɡ ɚ l']\n",
      "\n",
      "\n",
      "Truth: Only one gigabyte remaining.\n",
      "/export/common/data/corpora/ASR/commonvoice/en/clips/common_voice_en_18658102.mp3\n",
      "['ɔ n l i w ʌ n ɡ ɪ ɡ ʌ b aɪ t ɹ ɪ m eɪ n ɪ ŋ']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in dataset.shuffle().select(range(10)):\n",
    "    # if data[\"lang\"] != \"us\":\n",
    "    #     continue\n",
    "\n",
    "    print(f'Truth: {data[\"transcript\"]}')\n",
    "    print(data[\"filename\"])\n",
    "    # input_values = processor(ds[7][\"audio\"][\"array\"], return_tensors=\"pt\").input_values\n",
    "    input_values = processor(data[\"signal\"], sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "    logits = model(input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    print(transcription)\n",
    "    print(\"\\n\")\n",
    "    # print(f\"Truth: {ds[7]['text']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal, sr = torchaudio.load(\"/export/common/data/corpora/ASR/commonvoice/en/clips/common_voice_en_18645667.mp3\")\n",
    "signal, sr = torchaudio.load(\"/exp/nbafna/data/edacc/edacc_v1.0/data/EDACC-C22.wav\")\n",
    "# EDACC-C22.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files for en from /exp/jvillalba/corpora/voxlingua107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56537432f0ab426da7f169c5cba34adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/utils/dataloading\")\n",
    "from vl107 import load_vl107\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/exp/jvillalba/corpora/voxlingua107/en/5Ve0wXtmATI__U__S332---2167.620-2177.410.wav\n",
      "['ð ə l æ n d h iː ɹ uː l z f ɑː t ə ð ə n oː θ b ʌ t j ɛ t ɪ n h ɚ h ɑː t t ʃ iː n oʊ z ð ə t ʃ']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/en/a7Z0SkS8nFs__U__S0---0250.130-0266.530.wav\n",
      "['aʊ l s oʊ æ z ð ə ɡ ɛ ɹ ɔ k w ɨ ɛ s t ɐ æ n d ɡ ɛ ɹ ɔ m i n z w oː t ɹ æ v əl d ɪ n h ɪ z t aɪ m d ə n ɑː ts i']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/en/t4e2CHFMWDQ__U__S0---0394.010-0410.480.wav\n",
      "['ɪ n m aɪ ɹ ɪ s p ɔ n s ə b ɪ l ɪ t i f oʊ m aɪ n uː j uː z ə k oʊ dʒ ɔ n s m ɪ t oː l ɑː n ɪ t ə d uː ɪ z j uː z m aɪ p ə s ɛ n tʃ ə t s']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/en/t4e2CHFMWDQ__U__S0---0394.010-0410.480.wav\n",
      "['s aɪ n w ɪ tʃ ɪ z ə ɡ eɪ n j uː z f oː m aɪ w aɪ l m aɪ s æ tʃ a n d a k æ n t aɪ p ɪ n']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/en/OszbTEVdxjw__U__S11---0112.270-0124.620.wav\n",
      "['ɐ ɹ ɪ k w ɛ s t k ʌ m ɪ n ɪ n f ɹ ʌ m ð ɪ ɪ n t ɚ n ɛ t ɐ w ɛ b p eɪ dʒ ɹ ɪ k w ɛ s t ə n ɛ f t iː p iː iː m eɪ l iː v ɚ h æ k ɚ z']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/en/Zn0FpMFZWOo__U__S27---0480.200-0499.580.wav\n",
      "['n ɑː ʃ uː l ɐ h æ z p l eɪ d ð ə m ɔ n s t ɚ ɪ n ɛ v ɹ ɹ i p ɹ ə d ʌ k ʃ ə ɛ v ɹ i p ɹ ə d ʌ k ʃ ə n ʌ v ð ɪ s ʃ ɚ']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/en/OszbTEVdxjw__U__S11---0112.270-0124.620.wav\n",
      "['z k aʊ ɾ ɚ s t ɹ aɪ k s h oː s ɛ n i θ ɪ ŋ k ʌ m ɪ n ɪ n f ʌ m ð ɪ ɪ n ɚ n ɛ t ɪ z ɡ ɔ n ə b iː ɹ iː d ɚ ɹ ɛ k t ɪ d t ə ð ɪ s w ʌ n p ə t ɪ k j ɪ l ɚ m ə ʃ iː n']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/en/d30n-YxOHo4__U__S1---0063.330-0072.730.wav\n",
      "['s oː m oː s t ʌ v ð ə s ɪ k j ɔ r ɪ ɾ i b r iː tʃ ə z k m f ɹ ʌ m ʌ n ɪ n f oː m d æ n a n t r i n p ɚ s ə n z h w ɪ tʃ ɡ ɪ v ɪ n f ɚ m eɪ ʃ ə n t ʊ ɐ t oː d p ɑː t i ɔ']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/en/mzfg0RGJnV8__U__S118---0541.000-0547.040.wav\n",
      "['aɪ m d iː p l i d ɪ s ə p oɪ n t ɪ d w ɪ ð ə s ə p ɹ iː m k oʊ t s f aɪ n əl d ɪ k ɹ iː aɪ m h ɚ t w eɪ d æ n d iː p æ n d aɪ k eɪ n t h aɪ d ɪ t']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/en/Zn0FpMFZWOo__U__S27---0480.200-0499.580.wav\n",
      "['ɹ oʊ ð iː k m ɪ t ɪ d v ɛ ɹ i f ɪ z ɪ k ʊ p ɑː æ n d h iː ɡ eɪ v ɑː n d ɪ t ɛ m p ɚ s ɛ n t t ə ð ə ɹ ɪ n t ɹ ɛ s t ɪ ŋ p oʊ']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vl = load_vl107(per_lang=10, lang=\"en\")\n",
    "\n",
    "for data in vl.shuffle().select(range(10)):\n",
    "    # if data[\"lang\"] != \"us\":\n",
    "    #     continue\n",
    "\n",
    "    # print(f'Truth: {data[\"transcript\"]}')\n",
    "    print(data[\"audio_file\"])\n",
    "    # input_values = processor(ds[7][\"audio\"][\"array\"], return_tensors=\"pt\").input_values\n",
    "    input_values = processor(data[\"signal\"], sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "    logits = model(input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    print(transcription)\n",
    "    print(\"\\n\")\n",
    "    # print(f\"Truth: {ds[7]['text']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files for hi from /exp/jvillalba/corpora/voxlingua107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a959ab851bf2418ea53b3a937bc9e104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/exp/jvillalba/corpora/voxlingua107/hi/zVdpq5lprLs__U__S1---0018.420-0027.420.wav\n",
      "['t aɪ ʃ u r u a t m i i ɡ b eː z b ɔ l p l e r t e p i r u n h o n e d o h a z a r d e r a m i d a']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/hi/jw5LlzcI2hI__U__S0---2406.810-2424.690.wav\n",
      "['d i a ɕ a z a s a l o r i v u t n a b i l e l o r d i a ɔ r a p n a dʒ a s t i f i k e ʃ ə n d e n e s a k a r e r e a ʃ i r aɪ m w a u l']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/hi/yax1Op0EtW4__U__S152---0361.840-0371.960.wav\n",
      "['a r k a f i l o p u n ɡ i n a a m m a n k e s a l t e a l s k u n m a dʒ a r n d a s k a d e t e dʒ a p k i u n k u a']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/hi/K4bzT5z3DmE__U__S1---0123.010-0137.170.wav\n",
      "['i n ɡ a r a p e l o m e i s r o k e k u l p a s p e l o r s a m i l t e i k e a l a v a n a s a j u ɾ o p i n i s p e s j a z e n s i o r b a l ɡ']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/hi/UogodRBLEWM__U__S24---0187.100-0205.680.wav\n",
      "['t a l u k a s w a m i b e n a e t a a r e n d r e n i s u a l k o t u r e k ʃ ə dʒ a n k ʌ r p e s e n t a f u r v o k d i p a v e l i m a n aɪ']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/hi/jw5LlzcI2hI__U__S0---2406.810-2424.690.wav\n",
      "['aː n a k i ʃ aː d i s d i b e k m e k u s k ə n k l uː dʒ ə n ɔ k e s i n i a l a s p e r o n t e l e k a a f r eː s i a ɾ e d a r e k a']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/hi/UogodRBLEWM__U__S24---0187.100-0205.680.wav\n",
      "['b ɪ l a m i n ʃ e t r m i a n n i k uː t m h o t s o v i s l iː m a n aɪ j dʒ a t a h e k j o k i e z d i n n aɪ a n a tʃ k i ʃ y r a d p a ɡ v a n k']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/hi/UogodRBLEWM__U__S24---0187.100-0205.680.wav\n",
      "['o b h u ɡ l e ɡ a k e r k i dʒ a t i h e e s k e l a v a e s i d e n p a ɡ w a n v e ʃ n u n i d a dʒ a b a l i k u p a']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/hi/IlHPX5wNDqY__U__S105---0374.040-0381.850.wav\n",
      "['ʃ aː m k i e b a t k o d u t aɪ m o t a h e r a t k i d aɪ m e a p k u k a l i k a p r e k u r i k a l e k a p r e p e h e n d']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/hi/K4bzT5z3DmE__U__S1---0123.010-0137.170.wav\n",
      "['h aɪ r e z ʊ l uː s ə n r i m o t z ɛ n z ɪ ŋ ɪ k w y p m ɛ n t l e ɡ a r ɡ aɪ a t a d ɪ s m e ɡ a r a p e l o d s a m i l t i']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vl = load_vl107(per_lang=10, lang=\"hi\")\n",
    "\n",
    "for data in vl.shuffle().select(range(10)):\n",
    "    # if data[\"lang\"] != \"us\":\n",
    "    #     continue\n",
    "\n",
    "    # print(f'Truth: {data[\"transcript\"]}')\n",
    "    print(data[\"audio_file\"])\n",
    "    # input_values = processor(ds[7][\"audio\"][\"array\"], return_tensors=\"pt\").input_values\n",
    "    input_values = processor(data[\"signal\"], sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "    logits = model(input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    print(transcription)\n",
    "    print(\"\\n\")\n",
    "    # print(f\"Truth: {ds[7]['text']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files for yo from /exp/jvillalba/corpora/voxlingua107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ecf5eca7684431b4a37bd61e485334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/exp/jvillalba/corpora/voxlingua107/yo/O0stkM3BTDc__U__S294---2139.640-2152.290.wav\n",
      "['a b a t u l i a l e ts i k a a m a b a v a m b e l i m e l i a l e p m i w a a s i l e k o i b e r i w a a b o j o n dʒ u']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/yo/s6tJ6OqIAcY__U__S104---1656.070-1667.890.wav\n",
      "['n t b a a b ə d s ʊ l w a a t uː z e s a l o d a w a m ɛ t a l a n i d w a t r iː m']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/yo/equuzFg4XzI__U__S279---2126.830-2146.410.wav\n",
      "['l a k s a k s iː m t ʊ ɹ ɪ t ʊ l ɪ f t h ɪ m s ɛ l f w ɔ ɔ p w ɪ ð ɐ p i l o a n d h iː d s ɛ d ð ə tʃ a w a d r o s']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/yo/sF_aTeSig5A__U__S91---0572.800-0586.570.wav\n",
      "['m ɑ5 p i5 ou5 ɑ5 j i5 t u5 l ɑ5 onɡ5 m ɑ5 j u5 ɑ5']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/yo/equuzFg4XzI__U__S279---2126.830-2146.410.wav\n",
      "['d ə l iː d ts ɛ z ð ə l iː d p o z i ʃ ə n b i k ɔ s j y aɪ ɛ n tʃ a dʒ j uː t ɛ l d e m a n t u t u s l aɪ f']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/yo/yERqavpZHnM__U__S184---1138.300-1144.870.wav\n",
      "['a d n a tʃ a b a t eː z eː d ɪ s a r iː v ɑː ʃ ɛ t ɑː ɔ ɔ ɔ t l ɔ ɔ n ɔ ɔ t m a']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/yo/IWHSR93Kz6E__U__S239---1997.000-2006.950.wav\n",
      "['b e ts u k i p j o h o m t e b a d o n t u l a iː n o r i f u m d o d e m o k ɹ e t i d o j o ɡ e ts i w o d e l e o r o o r']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/yo/O0stkM3BTDc__U__S294---2139.640-2152.290.wav\n",
      "['p o ŋ o t o d aː d a n i n u tʃ e k a m eɪ ŋ h uː b i w ɔ l i t o d i m a l s e b ɛ ŋ b aː m e n a o l o s a n u v a l oɪ l i']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/yo/L5VZU0u5vHs__U__S1---1696.050-1713.400.wav\n",
      "['iː z ɔ s ɛ v w ə n b r a z ɪ b b p a n j uː s ɛ m aɪ f ɑː d ɜ s oː ʃ i m i l ɛ t s aɪ z a']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/yo/L5VZU0u5vHs__U__S1---1696.050-1713.400.wav\n",
      "['w a w a ʃ i s o x a r j a x w a l e k w a a b a h p l a w e t o p ɹ ɾ e m w o s ð e u n u k w a n d e s u n e b a r e l e tʃ o tʃ']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vl = load_vl107(per_lang=10, lang=\"yo\")\n",
    "\n",
    "for data in vl.shuffle().select(range(10)):\n",
    "    # if data[\"lang\"] != \"us\":\n",
    "    #     continue\n",
    "\n",
    "    # print(f'Truth: {data[\"transcript\"]}')\n",
    "    print(data[\"audio_file\"])\n",
    "    # input_values = processor(ds[7][\"audio\"][\"array\"], return_tensors=\"pt\").input_values\n",
    "    input_values = processor(data[\"signal\"], sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "    logits = model(input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    print(transcription)\n",
    "    print(\"\\n\")\n",
    "    # print(f\"Truth: {ds[7]['text']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files for ka from /exp/jvillalba/corpora/voxlingua107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a616893140624735abe9582ce668db52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/exp/jvillalba/corpora/voxlingua107/ka/nrsc8Zihnug__U__S129---0653.870-0665.950.wav\n",
      "['o s a p x u l ʃ iː a m iː r o m t e l i d i ɡ i ts u l e b e b iː ə n e m o k a l a k i t a m u l a ts i l o b i s t w a r s a s r e s i t']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/ka/GrVb_8Jb2W4__U__S15---0030.900-0043.780.wav\n",
      "['a r s e v o s p o l o d w a r a d e b i d e s a r m u d e n e v i m i ʃ e s a x e s i n a m b y l e ʃ i r a s t a n ʃ eː z d e b o k o n d e s a k']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/ka/W4OKP3pubPg__U__S15---0122.450-0136.140.wav\n",
      "['f t ə d a n i ɡ a m o ts t iː l e b ɐ m a l s r aʊ s ə m eː ɡ l e d a oː t k iː ʃ v iː l i t a r m ɔ ɡ iː']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/ka/JUMPYYVwyVk__U__S150---1909.450-1921.070.wav\n",
      "['a ts ɪ s aɪ ɪ s t s t i n ŋ tʃ ɪ m ɪ d ɛ s s i a k a l ɔ ð ɔ n oː h ə m ɛ d a tʃ ɛ m i b ɪ ʁ uː ɹ ɚ ɐ b e d a tʃ e m']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/ka/KmuC3w2Mmb0__U__S11---0103.950-0113.560.wav\n",
      "['p r o k u r a t u r a m ɡ a m u z i s p b k a m u z e v i s p a r ɡ y p ʃ i ʊ n d a k o n ɡ r e t u l a t t k v a s e s a d a m i a n i e']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/ka/_9iFYrFRCA0__U__S182---1230.710-1250.480.wav\n",
      "['d a e s i s t ɔ ɾ r i uː l i ʃ u ɡ l i d e k o n t i n ə n t o ɾ i e v ə r u p i d a n m o m a v a l i s a p t r e x o v l i b r i t a n e l i t a']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/ka/nrsc8Zihnug__U__S129---0653.870-0665.950.wav\n",
      "['x a z i ɡ aʊ s a k e n d e r u l t h a n a s t o r o b a s t a r m b e r t e b a ʃ iː d o m a ð o r o ɡ o s m u ɡ e k s e n d i b a s a k a t o r u s p a l a m i t b a k a s s u l ts e l s']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/ka/OzE8rxL9Yzc__U__S5---0027.660-0042.090.wav\n",
      "['ð iː l a m ʃ i d ɔ v i s eː s e ɡ i m o ɡ e s a l m ə v i θ aɪ s e t h a m a r l e v u l n o t a z e a x p t aʊ a n ə b u l i ɔ r s a b']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/ka/nnkBmgkPYAs__U__S6---0056.650-0062.680.wav\n",
      "['n u x i s z a k a t a l a s a d a b e l k a n i s e k a tʃ e t ɡ e z a i ŋ ɡ i l o a z e']\n",
      "\n",
      "\n",
      "/exp/jvillalba/corpora/voxlingua107/ka/S7pQB23FQXk__U__S28---0265.190-0273.850.wav\n",
      "['ts iː r w a l o ts a d a a m t a z r v t h a n iː ʁ o ɡ a x ts o n e l i o t ʁ ts l eː a n i s a ts aʊ l y b l e b i s a d a s m r d e l eː m e r a k i t ʁ a s e d']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vl = load_vl107(per_lang=10, lang=\"ka\")\n",
    "\n",
    "for data in vl.shuffle().select(range(10)):\n",
    "    # if data[\"lang\"] != \"us\":\n",
    "    #     continue\n",
    "\n",
    "    # print(f'Truth: {data[\"transcript\"]}')\n",
    "    print(data[\"audio_file\"])\n",
    "    # input_values = processor(ds[7][\"audio\"][\"array\"], return_tensors=\"pt\").input_values\n",
    "    input_values = processor(data[\"signal\"], sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "    logits = model(input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    print(transcription)\n",
    "    print(\"\\n\")\n",
    "    # print(f\"Truth: {ds[7]['text']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files for hi from /exp/jvillalba/corpora/voxlingua107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bc5910f99d4044a4212ac5ee6bc312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k aː ʃ a b m i r e s a d b a n e r ɐ h i n e t i ʃ k u m a r p ʌ r i s a v a l h eː aɪ s a k j uː h u r aɪ k u k j', 'aː p n e t a s v i r d e k h iː h aː p a r n a v a d a k i a m u ŋ ɡ e r tʃ e l t e m u ŋ ɡ e r dʒ o p e l e s eː s a m p r d aɪ k i n s a k i aː ɡ m e t h a dʒ a l r aː t h a', 'v a h k a l s a m p r o d aː k m a h ɔ l ɡ a r m eː r i l v i k i z a m i n p a r h a n u m aː n dʒ i k i m u r t i h a t aɪ dʒ aː n i k e v v i r o', 'v o l t oː r t uː k a s e n i k o p o r k a f i ɡ e h r a s e h u a dʒ o p a r ð i s m eɪ i k n eɪ dʒ a ɡ e p ɔ h o tʃ k aɪ', 'r aɪ n ə dʒ uː m i s a r a r aɪ ʃ p a t ə h a l j a p ɛ oː r j uː ə p dʒ oː l ə r k a t a ð ʊ ɔ b ə l a dʒ a b a n dʒ a p aɪ n', 'e t a r b aː v i uː ɡ a ɡ e r v e a n d e k i k a m i o d e l e ɡ iː t o v ɛ k e d e v o r ɡ o b u n d e n i k l i d e v a k o d uː d e e v e ʃ e r p o o dʒ l e', 'k a h iː n t u r ɡ a t n a h o ɡ a j i t o h a m a r a dʒ iː v ə n v a d i t h o d aː ɡ a h a m a r a n a a m a r e n aː', 'm ɡ i r o s n i k a t a m o dʒ aɪ ɡ i a k l e s r u ɡ aɪ dʒ a m h u p a l', 'i t h e ɡ i n a ɡ ʃ dʒ i s p iː t a r ʌ v dʒ aː ŋ ɡ ɨ u n t ɡ a m a n t r i b a n a p a k k a h e a b s a p s i p e h l ɡ i d i k', 'n a h u ɡ a k i b i d h a n ts a p a a d j e k ʃ o ɪ n s a b h i v i d h aɪ k u k e s t iː f m a n z u r k a r i ŋ ɡ j a n a h i ŋ u s k e b a d', 'a ɡ r p i t aː d i x o t o p e ʃ ə n ɪ s t o m a l l a t a r i p r e ɡ n e n s i m i s i e v n e i l a k k t i ʃ ə n m i', 's e f n i b l e d i n d i s o d o s o t a k s i r o p aɪ l s o a l ts o r o d e s k a p r e ɡ n a', 'a k ʌ r i a ɡ ʌ r a p k u u l u k t o l o b oː t p o s e n d i t o l aɪ k r i ʃ e r k ʌ r i k o m e n d k ʌ r i t e n n i v a t', 'aʊ l f i l i p i n s k a m p a ɲ uː n ɪ s k a s u p ə r b r ɔ n d ə k aɪ s k oː ɛ w a ɾ d ə t k j a h u v a h aɪ t k aː', 'j a h a k e b a ʃ i n d e p o ɡ a s tʃ u n aː k a r o p l a ɡ a k a r u s k a b a h i ʃ k a r k a r t e r e t e h e m u l b', 'h u t s u d h aː k e b i n a d o z a k s i z i n d ɡ eɪ dʒ i n e k o m a dʒ i b u r i a h a k e l l o ɡ p a k i s t aː n m u r d a b a']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vl = load_vl107(per_lang=10, lang=\"hi\")\n",
    "\n",
    "input_values = processor(vl[\"signal\"], sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)\n",
    "print(transcription)\n",
    "print(\"\\n\")\n",
    "# print(f\"Truth: {ds[7]['text']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/home/hltcoe/nbafna/projects/mitigating-accent-bias-in-lid/utils/dataloading\")\n",
    "from edacc import load_edacc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 76 audio files\n",
      "Recorded 122 speakers\n",
      "Loaded 13213 segments\n",
      "Sample: {'signal': array([-2.5101658e-04, -3.3711875e-04, -4.3454114e-04, ...,\n",
      "       -8.6554268e-05, -2.1143309e-04, -1.7558667e-04], dtype=float32), 'lang': 'en', 'accent': 'scottish', 'audio_file': 'EDACC-C08'}\n",
      "Accents: {'romanian', 'icelandic', 'pakistani', 'sinhalese', 'israeli', 'polish', 'catalan', 'lithuanian', 'colombian', 'dutch', 'macedonian', 'chilean', 'indian', 'montenegrin', 'scottish', 'mexican', 'indonesian', 'us', 'tagalog', 'russian', 'ecuadorian', 'jamaican', 'egyptian', 'brazilian', 'french', 'shona', 'irish', 'south african', 'ghanian', 'italian', 'vietnamese', 'spanish', 'nigerian', 'korean', 'chinese', 'american', 'filipino', 'japanese', 'bulgarian', 'uk', 'kenyan'}\n"
     ]
    }
   ],
   "source": [
    "edacc = load_edacc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/exp/nbafna/data/edacc/edacc_v1.0/data/EDACC-C31_P1.wav\n",
      "pakistani\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s ʌ m t aɪ m ð ə ɔ l d ə s t b ɹ ʌ ð ə ʌ w ɛ n h i ɪ z w ɚ k ɪ ŋ w ɪ ð ð ə æ v i t ɔ l j']\n",
      "\n",
      "\n",
      "/exp/nbafna/data/edacc/edacc_v1.0/data/EDACC-C30.wav\n",
      "romanian\n",
      "['n ɔ ð eɪ ɑː s oʊ t uː p ɚ f ɪ k t uː']\n",
      "\n",
      "\n",
      "/exp/nbafna/data/edacc/edacc_v1.0/data/EDACC-C29_P2.wav\n",
      "nigerian\n",
      "['a oː d ɪ z l aɪ ɪ n f ɹ ɔ n t ʌ v ð ɪ h aʊ s s oʊ æ z aɪ w ɔ z k ɔ m ɪ ŋ w iː d f oʊ s f iː d ɪ n oʊ d w ɔ s t']\n",
      "\n",
      "\n",
      "/exp/nbafna/data/edacc/edacc_v1.0/data/EDACC-C37_P1.wav\n",
      "spanish\n",
      "['t uː l ɛ n ð ɪ s s n uː s a ŋ ɛ t l iː s t n ɑː t b aɪ h a r t b ʌ t d ə b ɛ ɾ ɚ']\n",
      "\n",
      "\n",
      "/exp/nbafna/data/edacc/edacc_v1.0/data/EDACC-C43_P1.wav\n",
      "south african\n",
      "['k w ɪ tʃ ɪ z ð ə f aɪ n ɚ l j eɪ ɹ ʌ v h aɪ s k uː l h ɛ m s oʊ']\n",
      "\n",
      "\n",
      "/exp/nbafna/data/edacc/edacc_v1.0/data/EDACC-C43_P1.wav\n",
      "south african\n",
      "['aɪ θ ɪ ŋ k ɪ t w ʌ z ɐ b ɑː l ɪ t w ʌ z ə b ɑː d ʌ ʌ w aɪ t f æ m l i']\n",
      "\n",
      "\n",
      "/exp/nbafna/data/edacc/edacc_v1.0/data/EDACC-C61.wav\n",
      "irish\n",
      "['t ʌ v v ʌ v j ɚ d eɪ l i l aɪ f j uː n oː æ n d ɪ t ɐ ɡ ɛ n ɪ w ʌ z v ɛ ɹ i m ʌ tʃ j uː k eɪ k']\n",
      "\n",
      "\n",
      "/exp/nbafna/data/edacc/edacc_v1.0/data/EDACC-C46_P2.wav\n",
      "scottish\n",
      "['ʌ v k w ɔ l ɪ t i ʌ v l aɪ f ð eɪ h æ v s uː aɪ θ æ ŋ k l eɪ k j uː w iː p ɹ ɔ b ʌ b l i w oʊ n t']\n",
      "\n",
      "\n",
      "/exp/nbafna/data/edacc/edacc_v1.0/data/EDACC-C47_P2.wav\n",
      "irish\n",
      "['j iː ɡ ɔ b æ k t ə ð æ t n aʊ ɪ n ð ə l æ s t k ɔ p ə l ʌ v j ɚ s p iː p l ɚ s t ɑː t ɪ ŋ t ə ɡ ɹ oː ð ɚ']\n",
      "\n",
      "\n",
      "/exp/nbafna/data/edacc/edacc_v1.0/data/EDACC-C43_P1.wav\n",
      "south african\n",
      "['z v ɛ ɹ i w ɛ s t ə n f uː d s oʊ aɪ d uː ɛ n dʒ oʊ iː t iː ɐ k ʌ ɹ i w ɛ n aɪ ɡ ɑː t æ m']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edacc = edacc.shuffle()\n",
    "for data in edacc.select(range(10)):\n",
    "    # if data[\"lang\"] != \"us\":\n",
    "    #     continue\n",
    "\n",
    "    # print(f'Truth: {data[\"transcript\"]}')\n",
    "    print(\"/exp/nbafna/data/edacc/edacc_v1.0/data/\"+data[\"audio_file\"]+\".wav\")\n",
    "    print(data[\"accent\"])\n",
    "    # input_values = processor(ds[7][\"audio\"][\"array\"], return_tensors=\"pt\").input_values\n",
    "    input_values = processor(data[\"signal\"], sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "    logits = model(input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    print(transcription)\n",
    "    print(\"\\n\")\n",
    "    # print(f\"Truth: {ds[7]['text']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hltcoe/nbafna/.conda/envs/accent_bias/lib/python3.12/site-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
      "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
      "/home/hltcoe/nbafna/.conda/envs/accent_bias/lib/python3.12/site-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
      "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
      "/home/hltcoe/nbafna/.conda/envs/accent_bias/lib/python3.12/site-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
      "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
      "/home/hltcoe/nbafna/.conda/envs/accent_bias/lib/python3.12/site-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
      "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_your_file.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplayback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m play\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the sound file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m sound \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath_to_your_file.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Play the sound\u001b[39;00m\n\u001b[1;32m      8\u001b[0m play(sound)\n",
      "File \u001b[0;32m~/.conda/envs/accent_bias/lib/python3.12/site-packages/pydub/audio_segment.py:808\u001b[0m, in \u001b[0;36mAudioSegment.from_wav\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_wav\u001b[39m(\u001b[38;5;28mcls\u001b[39m, file, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/accent_bias/lib/python3.12/site-packages/pydub/audio_segment.py:651\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m file, close_file \u001b[38;5;241m=\u001b[39m \u001b[43m_fd_or_path_or_tempfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m:\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m~/.conda/envs/accent_bias/lib/python3.12/site-packages/pydub/utils.py:60\u001b[0m, in \u001b[0;36m_fd_or_path_or_tempfile\u001b[0;34m(fd, mode, tempfile)\u001b[0m\n\u001b[1;32m     57\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fd, basestring):\n\u001b[0;32m---> 60\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_your_file.wav'"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# Load the sound file\n",
    "sound = AudioSegment.from_wav('path_to_your_file.wav')\n",
    "\n",
    "# Play the sound\n",
    "play(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accent_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
